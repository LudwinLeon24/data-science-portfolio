{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0vqbgi9ay0H"
   },
   "source": [
    "# Déjame escuchar la música"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhq_eyov_Zcs"
   },
   "source": [
    "# Contenido <a id='back'></a>\n",
    "\n",
    "* [Introducción](#intro)\n",
    "* [Etapa 1. Descripción de los datos](#data_review)\n",
    "    * [Conclusiones](#data_review_conclusions)\n",
    "* [Etapa 2. Preprocesamiento de datos](#data_preprocessing)\n",
    "    * [2.1 Estilo del encabezado](#header_style)\n",
    "    * [2.2 Valores ausentes](#missing_values)\n",
    "    * [2.3 Duplicados](#duplicates)\n",
    "    * [2.4 Conclusiones](#data_preprocessing_conclusions)\n",
    "* [Etapa 3. Prueba de hipótesis](#hypothesis)\n",
    "    * [3.1 Hipótesis 1: actividad de los usuarios y las usuarias en las dos ciudades](#activity)\n",
    "* [Conclusiones](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUC88oWjTJw2"
   },
   "source": [
    "## Introducción <a id='intro'></a>\n",
    "Como analista de datos, tu trabajo consiste en analizar datos para extraer información valiosa y tomar decisiones basadas en ellos. Esto implica diferentes etapas, como la descripción general de los datos, el preprocesamiento y la prueba de hipótesis.\n",
    "\n",
    "Siempre que investigamos, necesitamos formular hipótesis que después podamos probar. A veces aceptamos estas hipótesis; otras veces, las rechazamos. Para tomar las decisiones correctas, una empresa debe ser capaz de entender si está haciendo las suposiciones correctas.\n",
    "\n",
    "En este proyecto, compararás las preferencias musicales de las ciudades de Springfield y Shelbyville. Estudiarás datos reales de transmisión de música online para probar la hipótesis a continuación y comparar el comportamiento de los usuarios y las usuarias de estas dos ciudades.\n",
    "\n",
    "### Objetivo:\n",
    "Prueba la hipótesis:\n",
    "1. La actividad de los usuarios y las usuarias difiere según el día de la semana y dependiendo de la ciudad.\n",
    "\n",
    "\n",
    "### Etapas\n",
    "Los datos del comportamiento del usuario se almacenan en el archivo `/datasets/music_project_en.csv`. No hay ninguna información sobre la calidad de los datos, así que necesitarás examinarlos antes de probar la hipótesis.\n",
    "\n",
    "Primero, evaluarás la calidad de los datos y verás si los problemas son significativos. Entonces, durante el preprocesamiento de datos, tomarás en cuenta los problemas más críticos.\n",
    "\n",
    "Tu proyecto consistirá en tres etapas:\n",
    " 1. Descripción de los datos.\n",
    " 2. Preprocesamiento de datos.\n",
    " 3. Prueba de hipótesis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1hmfXC_Zcs"
   },
   "source": [
    "## Etapa 1. Descripción de los datos <a id='data_review'></a>\n",
    "\n",
    "Abre los datos y examínalos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57eAOGIz_Zcs"
   },
   "source": [
    "Necesitarás `pandas`, así que impórtalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "AXN7PHPN_Zcs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Importar pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG23P8tt_Zcs"
   },
   "source": [
    "Lee el archivo `music_project_en.csv` de la carpeta `/datasets/` y guárdalo en la variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "fFVu7vqh_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Leer el archivo y almacenarlo en df\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\n",
    "Cuidado!<br/>\n",
    "\n",
    "La manera de leer los datos es erronea, lo he corregido para que puedas ver la diferencia\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDoOMd3uTqnZ"
   },
   "source": [
    "Muestra las 10 primeras filas de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "oWTVX3gW_Zct",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userID                        Track            artist   genre  \\\n",
      "0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n",
      "1  55204538  Delayed Because of Accident  Andreas Rönnberg    rock   \n",
      "2    20EC38            Funiculì funiculà       Mario Lanza     pop   \n",
      "3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n",
      "4  E2DC1FAE                  Soul People        Space Echo   dance   \n",
      "5  842029A1                       Chains          Obladaet  rusrap   \n",
      "6  4CB90AA5                         True      Roman Messer   dance   \n",
      "7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n",
      "8  8FA1D3BE                     L’estate       Julia Dalia  ruspop   \n",
      "9  E772D5C0                    Pessimist               NaN   dance   \n",
      "\n",
      "        City        time        Day  \n",
      "0  Shelbyville  20:28:33  Wednesday  \n",
      "1  Springfield  14:07:09     Friday  \n",
      "2  Shelbyville  20:58:07  Wednesday  \n",
      "3  Shelbyville  08:37:09     Monday  \n",
      "4  Springfield  08:34:34     Monday  \n",
      "5  Shelbyville  13:09:41     Friday  \n",
      "6  Springfield  13:00:07  Wednesday  \n",
      "7  Springfield  20:47:49  Wednesday  \n",
      "8  Springfield  09:17:40     Friday  \n",
      "9  Shelbyville  21:20:49  Wednesday  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))# Obtener las 10 primeras filas de la tabla df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO73Kwic_Zct"
   },
   "source": [
    "Obtén la información general sobre la tabla con un comando. Conoces el método que muestra la información general que necesitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSf2kIb-_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df.shape)# Obtener la información general sobre nuestros datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQ2Iwbr_Zct"
   },
   "source": [
    "Estas son nuestras observaciones sobre la tabla. Contiene siete columnas. Almacenan los mismos tipos de datos: `object`.\n",
    "\n",
    "Según la documentación:\n",
    "- `' userID'`: identificador del usuario o la usuaria;\n",
    "- `'Track'`: título de la canción;\n",
    "- `'artist'`: nombre del artista;\n",
    "- `'genre'`: género de la pista;\n",
    "- `'City'`: ciudad del usuario o la usuaria;\n",
    "- `'time'`: la hora exacta en la que se reprodujo la canción;\n",
    "- `'Day'`: día de la semana.\n",
    "\n",
    "Podemos ver tres problemas con el estilo en los encabezados de la tabla:\n",
    "1. Algunos encabezados están en mayúsculas, otros en minúsculas.\n",
    "2. Hay espacios en algunos encabezados.\n",
    "3. `Detecta el tercer problema por tu cuenta y descríbelo aquí`.\n",
    "\n",
    "El mal uso de las comillas en algunos nombres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCB6-dXG_Zct"
   },
   "source": [
    "### Escribe observaciones de tu parte. Estas son algunas de las preguntas que pueden ser útiles: <a id='data_review_conclusions'></a>\n",
    "\n",
    "`1.   ¿Qué tipo de datos tenemos a nuestra disposición en las filas? ¿Y cómo podemos entender lo que almacenan las columnas?`\n",
    "Cada fila representa una interacción de usuario, como la reproducción de una canción. Contiene información sobre el usuario, la canción reproducida, el artista, el género, la ubicación del usuario, el momento exacto de la reproducción y el día de la semana.\n",
    "\n",
    "Columnas:\n",
    "'userID': Identificador único del usuario, lo que nos permite rastrear las acciones de un usuario individual.\n",
    "'Track': Título de la canción reproducida, importante para analizar preferencias musicales.\n",
    "'artist': Artista de la canción, útil para medir popularidad.\n",
    "'genre': Género musical, relevante para clasificar preferencias musicales.\n",
    "'City': Ciudad del usuario, lo que permite análisis geográficos.\n",
    "'time': Hora exacta de la reproducción, que puede usarse para patrones temporales.\n",
    "'Day': Día de la semana, útil para explorar tendencias semanales.\n",
    "\n",
    "`2.   ¿Hay suficientes datos para proporcionar respuestas a nuestra hipótesis o necesitamos más información?`\n",
    "Los datos incluyen información detallada sobre canciones, artistas, géneros, ubicación y tiempo, lo cual es útil para analizar hábitos de escucha y tendencias geográficas/temporales.\n",
    "Limitaciones:\n",
    "No hay datos sobre la duración de la escucha o si la canción fue escuchada completamente.\n",
    "No se incluye información demográfica del usuario (como edad o género), lo que podría ser relevante dependiendo de la hipótesis.\n",
    "No se detalla si hay datos incompletos o representatividad insuficiente en ciertas ciudades o géneros.\n",
    "\n",
    "`3.   ¿Notaste algún problema en los datos, como valores ausentes, duplicados o tipos de datos incorrectos?`\n",
    "Problemas observados:\n",
    "Los encabezados tienen inconsistencias de formato (espacios, mayúsculas/minúsculas, comillas).\n",
    "Todas las columnas tienen el tipo de datos object, lo que podría no ser apropiado para columnas como 'time' (debería ser un tipo de tiempo) o 'Day' (posiblemente una categoría).\n",
    "Problemas por verificar:\n",
    "Valores ausentes: Es importante comprobar si hay columnas o filas con valores nulos que podrían afectar el análisis.\n",
    "Duplicados: Si hay filas duplicadas, podrían inflar o sesgar los resultados.\n",
    "Datos inconsistentes: Por ejemplo, errores tipográficos en 'genre' o 'City' podrían dificultar el agrupamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYF6Ub9_Zct"
   },
   "source": [
    "## Etapa 2. Preprocesamiento de datos <a id='data_preprocessing'></a>\n",
    "\n",
    "El objetivo aquí es preparar los datos para que sean analizados.\n",
    "El primer paso es resolver cualquier problema con los encabezados. Luego podemos avanzar a los valores ausentes y duplicados. Empecemos.\n",
    "\n",
    "Corrige el formato en los encabezados de la tabla.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaKXr29_Zct"
   },
   "source": [
    "### Estilo del encabezado <a id='header_style'></a>\n",
    "Muestra los encabezados de la tabla (los nombres de las columnas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKOTdF_Q_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mostrar los encabezados originales\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\n",
    "Cuidado!<br/>\n",
    "\n",
    "Los datos se deben leer solo una vez al inicio del proyecto, si se vuelven a leer todo el progreso que hayas hecho se pierde\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj5534cv_Zct"
   },
   "source": [
    "Cambia los encabezados de la tabla de acuerdo con las reglas del buen estilo:\n",
    "* Todos los caracteres deben ser minúsculas.\n",
    "* Elimina los espacios.\n",
    "* Si el nombre tiene varias palabras, utiliza snake_case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu0zkfe5zNJe"
   },
   "source": [
    "Anteriormente, aprendiste acerca de la forma automática de cambiar el nombre de las columnas. Vamos a aplicarla ahora. Utiliza el bucle for para iterar sobre los nombres de las columnas y poner todos los caracteres en minúsculas. Cuando hayas terminado, vuelve a mostrar los encabezados de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6I_RwwMhzM4e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "# Mostrar los encabezados originales\n",
    "print(\"Encabezados originales:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Cambiar los nombres de las columnas a minúsculas utilizando un bucle for\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "# Mostrar los encabezados después de convertir a minúsculas\n",
    "print(\"\\nEncabezados después de poner todo en minúsculas:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pweIRxjSzPYW"
   },
   "source": [
    "Ahora, utilizando el mismo método, elimina los espacios al principio y al final de los nombres de las columnas e imprime los nombres de las columnas nuevamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVQXbFyJzSYl",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "# Mostrar los encabezados originales\n",
    "print(\"Encabezados originales:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Cambiar los nombres de las columnas a minúsculas y eliminar espacios al principio y al final\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# Mostrar los encabezados después de eliminar los espacios y convertir a minúsculas\n",
    "print(\"\\nEncabezados después de eliminar los espacios y poner todo en minúsculas:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCb8MW1JzURd"
   },
   "source": [
    "Necesitamos aplicar la regla de snake_case a la columna `userid`. Debe ser `user_id`. Cambia el nombre de esta columna y muestra los nombres de todas las columnas cuando hayas terminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISlFqs5y_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "# Mostrar los encabezados originales\n",
    "print(\"Encabezados originales:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Cambiar los nombres de las columnas a minúsculas y eliminar espacios al principio y al final\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\n",
    "df.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n",
    "\n",
    "# Mostrar los encabezados después del cambio\n",
    "print(\"\\nEncabezados después de aplicar snake_case a 'userID':\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dqbh00J_Zct"
   },
   "source": [
    "Comprueba el resultado. Muestra los encabezados una vez más:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4NOAmTW_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "# Mostrar los encabezados originales\n",
    "print(\"Encabezados originales:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Cambiar los nombres de las columnas a minúsculas y eliminar espacios al principio y al final\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\n",
    "df.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n",
    "\n",
    "# Mostrar los encabezados después del cambio\n",
    "print(\"\\nEncabezados después de aplicar snake_case a 'userID':\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ISfbcfY_Zct"
   },
   "source": [
    "### Valores ausentes <a id='missing_values'></a>\n",
    " Primero, encuentra el número de valores ausentes en la tabla. Debes utilizar dos métodos en una secuencia para obtener el número de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "RskX29qr_Zct",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id track artist genre         city      time        day\n",
      "15     E3C5756F   NaN    NaN   NaN  Springfield  09:24:51     Monday\n",
      "35     A8AE9169   NaN    NaN   NaN  Springfield  08:56:10     Monday\n",
      "161    364C85C0   NaN    NaN   NaN  Springfield  20:06:58     Monday\n",
      "210    C4990C90   NaN    NaN   NaN  Springfield  20:09:56     Monday\n",
      "216    22B27E80   NaN    NaN   NaN  Springfield  13:34:16     Monday\n",
      "...         ...   ...    ...   ...          ...       ...        ...\n",
      "64792  7D9627FD   NaN    NaN   NaN  Springfield  08:57:15     Monday\n",
      "64810  36CDD10A   NaN    NaN  folk  Springfield  13:44:53  Wednesday\n",
      "64930  A8AE9169   NaN    NaN   NaN  Springfield  08:54:17     Friday\n",
      "64950  414F229D   NaN    NaN   NaN  Springfield  14:41:26     Monday\n",
      "65021  83831D51   NaN    NaN   hip  Shelbyville  20:15:36     Friday\n",
      "\n",
      "[1343 rows x 7 columns]\n",
      "\n",
      "DataFrame después de reemplazar los valores ausentes:\n",
      "        user_id                              track            artist  \\\n",
      "0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n",
      "1      55204538        Delayed Because of Accident  Andreas Rönnberg   \n",
      "2        20EC38                  Funiculì funiculà       Mario Lanza   \n",
      "3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n",
      "4      E2DC1FAE                        Soul People        Space Echo   \n",
      "...         ...                                ...               ...   \n",
      "65074  729CBB09                            My Name            McLean   \n",
      "65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n",
      "65076  C5E3A0D5                          Jalopiina               NaN   \n",
      "65077  321D0506                      Freight Train     Chas McDevitt   \n",
      "65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n",
      "\n",
      "            genre         city      time        day  \n",
      "0            rock  Shelbyville  20:28:33  Wednesday  \n",
      "1            rock  Springfield  14:07:09     Friday  \n",
      "2             pop  Shelbyville  20:58:07  Wednesday  \n",
      "3            folk  Shelbyville  08:37:09     Monday  \n",
      "4           dance  Springfield  08:34:34     Monday  \n",
      "...           ...          ...       ...        ...  \n",
      "65074         rnb  Springfield  13:32:28  Wednesday  \n",
      "65075         hip  Shelbyville  10:00:00     Monday  \n",
      "65076  industrial  Springfield  20:09:26     Friday  \n",
      "65077        rock  Springfield  21:43:59     Friday  \n",
      "65078     country  Springfield  21:59:46     Friday  \n",
      "\n",
      "[65079 rows x 7 columns]\n",
      "\n",
      "Número de valores ausentes en todo el DataFrame:\n",
      "user_id       0\n",
      "track         0\n",
      "artist     7567\n",
      "genre      1198\n",
      "city          0\n",
      "time          0\n",
      "day           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "# Cambiar los nombres de las columnas a minúsculas y eliminar espacios\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\n",
    "df.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n",
    "\n",
    "# Mostrar los valores ausentes en una columna específica (por ejemplo 'track')\n",
    "print(df[df[\"track\"].isna()])\n",
    "\n",
    "# Rellenar los valores ausentes con 'unknown'\n",
    "df[\"track\"].fillna('unknown', inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame después de reemplazar los valores ausentes\n",
    "print(\"\\nDataFrame después de reemplazar los valores ausentes:\")\n",
    "print(df)\n",
    "\n",
    "# Ver el número total de valores ausentes\n",
    "print(\"\\nNúmero de valores ausentes en todo el DataFrame:\")\n",
    "print(df.isna().sum())# Calcular el número de valores ausentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSv2laPA_Zct"
   },
   "source": [
    "Reemplazar los valores ausentes en las columnas `'track'`, `'artist'` y `'genre'` con el string `'unknown'`. Como mostramos anteriormente en las lecciones, la mejor forma de hacerlo es crear una lista que almacene los nombres de las columnas donde se necesita el reemplazo. Luego, utiliza esta lista e itera sobre las columnas donde se necesita el reemplazo haciendo el propio reemplazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KplB5qWs_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#python\n",
    "#Copy\n",
    "#Edit\n",
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "# Cambiar los nombres de las columnas a minúsculas y eliminar espacios\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\n",
    "df.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n",
    "\n",
    "# Crear una lista de las columnas donde se necesita reemplazar los valores ausentes\n",
    "columns_to_fill = ['track', 'artist', 'genre']\n",
    "\n",
    "# Iterar sobre las columnas y reemplazar los valores ausentes con 'unknown'\n",
    "for column in columns_to_fill:\n",
    "    df[column].fillna('unknown', inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame después de reemplazar los valores ausentes\n",
    "print(\"\\nDataFrame después de reemplazar los valores ausentes:\")\n",
    "print(df)\n",
    "\n",
    "# Ver el número total de valores ausentes\n",
    "print(\"\\nNúmero de valores ausentes en todo el DataFrame:\")\n",
    "print(df.isna().sum())# Bucle en los encabezados reemplazando los valores ausentes con 'unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilsm-MZo_Zct"
   },
   "source": [
    "Ahora comprueba el resultado para asegurarte de que después del reemplazo no haya valores ausentes en el conjunto de datos. Para hacer esto, cuenta los valores ausentes nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq4nYRX4_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#lumna\n",
    "missing_counts = df.isna().sum()\n",
    "\n",
    "# Mostrar el número de valores ausentes por columna\n",
    "print(\"Número de valores ausentes por columna:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# Contar el total de valores ausentes en el DataFrame\n",
    "total_missing = missing_counts.sum()\n",
    "\n",
    "print(f\"\\nNúmero total de valores ausentes en el DataFrame: {total_missing}\")# Contar valores ausentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWKRtBJ3_Zct"
   },
   "source": [
    "### Duplicados <a id='duplicates'></a>\n",
    "Encuentra el número de duplicados explícitos en la tabla. Una vez más, debes aplicar dos métodos en una secuencia para obtener la cantidad de duplicados explícitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36eES_S0_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "duplicates = df.duplicated()\n",
    "\n",
    "# Contar el número de duplicados\n",
    "duplicate_count = duplicates.sum()\n",
    "\n",
    "# Mostrar el número de duplicados\n",
    "print(f\"El número de duplicados explícitos es: {duplicate_count}\")# Contar duplicados explícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot25h6XR_Zct"
   },
   "source": [
    "Ahora, elimina todos los duplicados. Para ello, llama al método que hace exactamente esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exFHq6tt_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Mostrar el DataFrame sin duplicados\n",
    "print(df_cleaned)# Eliminar duplicados explícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im2YwBEG_Zct"
   },
   "source": [
    "Comprobemos ahora si eliminamos con éxito todos los duplicados. Cuenta los duplicados explícitos una vez más para asegurarte de haberlos eliminado todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8PuNWQ0_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Eliminar duplicados y guardar el resultado en un nuevo DataFrame\n",
    "#df_cleaned = df.drop_duplicates()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Ahora, usa df_cleaned para cualquier operación posterior\n",
    "#duplicates_after_cleaning = df_cleaned.duplicated().sum()\n",
    "duplicates_after_cleaning = df.duplicated().sum()\n",
    "\n",
    "# Mostrar el número de duplicados después de la limpieza\n",
    "print(f\"El número de duplicados explícitos después de eliminar los duplicados es: {duplicates_after_cleaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFBsxAr_Zct"
   },
   "source": [
    "Ahora queremos deshacernos de los duplicados implícitos en la columna `genre`. Por ejemplo, el nombre de un género se puede escribir de varias formas. Dichos errores también pueden afectar al resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSjWwsOh_Zct"
   },
   "source": [
    "Para hacerlo, primero mostremos una lista de nombres de género únicos, ordenados en orden alfabético. Para ello:\n",
    "* Extrae la columna `genre` del DataFrame.\n",
    "* Llama al método que devolverá todos los valores únicos en la columna extraída.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIUcqzZN_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtener la columna de géneros\n",
    "genre_column = df['genre']\n",
    "\n",
    "# Obtener los valores únicos\n",
    "unique_genres = genre_column.unique()\n",
    "\n",
    "# Unificar los tipos de dato a cadena de texto\n",
    "unique_genres = unique_genres.astype(str)\n",
    "\n",
    "# Ordenar los géneros alfabéticamente usando NumPy\n",
    "sorted_unique_genres = np.sort(unique_genres)\n",
    "\n",
    "# Imprimir los géneros únicos ordenados alfabéticamente\n",
    "print(\"Géneros únicos ordenados alfabéticamente:\")\n",
    "print(sorted_unique_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qej-Qmuo_Zct"
   },
   "source": [
    "Busca en la lista para encontrar duplicados implícitos del género `hiphop`. Estos pueden ser nombres escritos incorrectamente o nombres alternativos para el mismo género.\n",
    "\n",
    "Verás los siguientes duplicados implícitos:\n",
    "* `hip`\n",
    "* `hop`\n",
    "* `hip-hop`\n",
    "\n",
    "Para deshacerte de ellos, crea una función llamada `replace_wrong_genres()` con dos parámetros:\n",
    "* `wrong_genres=`: esta es una lista que contiene todos los valores que necesitas reemplazar.\n",
    "* `correct_genre=`: este es un string que vas a utilizar como reemplazo.\n",
    "\n",
    "Como resultado, la función debería corregir los nombres en la columna `'genre'` de la tabla `df`, es decir, remplazar cada valor de la lista `wrong_genres` por el valor en `correct_genre`.\n",
    "\n",
    "Dentro del cuerpo de la función, utiliza un bucle `'for'` para iterar sobre la lista de géneros incorrectos, extrae la columna `'genre'` y aplica el método `replace` para hacer correcciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErNDkmns_Zct",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def replace_wrong_genres(wrong_genres, correct_genre):\n",
    "    for genre in wrong_genres:\n",
    "        # Reemplazar los géneros incorrectos con el correcto\n",
    "        df['genre'] = df['genre'].replace(genre, correct_genre)\n",
    "\n",
    "# Lista de géneros incorrectos que queremos reemplazar\n",
    "wrong_genres = ['hip', 'hop', 'hip-hop']\n",
    "\n",
    "# Género correcto que vamos a usar como reemplazo\n",
    "correct_genre = 'hip-hop'\n",
    "\n",
    "# Llamar a la función para reemplazar los géneros incorrectos\n",
    "replace_wrong_genres(wrong_genres, correct_genre)\n",
    "\n",
    "# Verificar los géneros después de la corrección\n",
    "unique_genres_after_correction = sorted(df['genre'].unique())\n",
    "print(\"Géneros únicos después de la corrección:\")\n",
    "print(unique_genres_after_correction)# Función para reemplazar duplicados implícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoBJxbA_Zct"
   },
   "source": [
    "Ahora, llama a `replace_wrong_genres()` y pásale tales argumentos para que retire los duplicados implícitos (`hip`, `hop` y `hip-hop`) y los reemplace por `hiphop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN5i2hpmSo09",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "replace_wrong_genres(wrong_genres=['hip', 'hop', 'hip-hop'], correct_genre='hiphop')\n",
    "\n",
    "# Verificar los géneros únicos después de la corrección\n",
    "unique_genres_after_correction = sorted(df['genre'].unique())\n",
    "print(\"Géneros únicos después de la corrección:\")\n",
    "print(unique_genres_after_correction)# Eliminar duplicados implícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQKF16_RG15m"
   },
   "source": [
    "Asegúrate de que los nombres duplicados han sido eliminados. Muestra la lista de valores únicos de la columna `'genre'` una vez más:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvixALnFG15m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unique_genres_after_correction = sorted(df['genre'].unique())\n",
    "print(\"Géneros únicos después de la corrección:\")\n",
    "print(unique_genres_after_correction)# Comprobación de duplicados implícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz6a9-7HQUDd"
   },
   "source": [
    "### Tus observaciones <a id='data_preprocessing_conclusions'></a>\n",
    "\n",
    "`Describe brevemente lo que has notado al analizar duplicados, cómo abordaste sus eliminaciones y qué resultados obtuviste.`\n",
    "\n",
    "Al analizar los duplicados en el DataFrame, observé que había dos tipos de duplicados:\n",
    "\n",
    "Duplicados explícitos: Es decir, filas exactas que se repetían en el DataFrame. Para eliminarlas, utilicé el método drop_duplicates() de Pandas\n",
    "\n",
    "Duplicados implícitos en la columna 'genre': Algunos géneros, como \"hip\", \"hop\" y \"hip-hop\", se escribían de formas inconsistentes, lo que podría afectar el análisis de las preferencias musicales. Para solucionar esto, creé la función replace_wrong_genres().\n",
    "\n",
    "Tras eliminar los duplicados explícitos, confirmé que no quedaban filas repetidas en el DataFrame.\n",
    "Después de corregir los duplicados implícitos en la columna genre, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WttZHXH0SqKk"
   },
   "source": [
    "## Etapa 3. Prueba de hipótesis <a id='hypothesis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im936VVi_Zcu"
   },
   "source": [
    "### Hipótesis: comparar el comportamiento del usuario o la usuaria en las dos ciudades <a id='activity'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwt_MuaL_Zcu"
   },
   "source": [
    "La hipótesis afirma que existen diferencias en la forma en que los usuarios y las usuarias de Springfield y Shelbyville consumen música. Para comprobar esto, usa los datos de tres días de la semana: lunes, miércoles y viernes.\n",
    "\n",
    "* Agrupa a los usuarios y las usuarias por ciudad.\n",
    "* Compara el número de canciones que cada grupo reprodujo el lunes, el miércoles y el viernes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dw_YMmT_Zcu"
   },
   "source": [
    "Realiza cada cálculo por separado.\n",
    "\n",
    "El primer paso es evaluar la actividad del usuario en cada ciudad. Recuerda las etapas dividir-aplicar-combinar de las que hablamos anteriormente en la lección. Tu objetivo ahora es agrupar los datos por ciudad, aplicar el método apropiado para contar durante la etapa de aplicación y luego encontrar la cantidad de canciones reproducidas en cada grupo especificando la columna para obtener el recuento.\n",
    "\n",
    "A continuación se muestra un ejemplo de cómo debería verse el resultado final:\n",
    "`df.groupby(by='....')['column'].method()`Realiza cada cálculo por separado.\n",
    "\n",
    "Para evaluar la actividad de los usuarios y las usuarias en cada ciudad, agrupa los datos por ciudad y encuentra la cantidad de canciones reproducidas en cada grupo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_Qs96oh_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#city_song_count = df.groupby(by='city')['Track'].count()\n",
    "city_song_count = df.groupby(by='city')['track'].count()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(city_song_count)# Contar las canciones reproducidas en cada ciudad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzli3w8o_Zcu"
   },
   "source": [
    "Ahora agrupemos los datos por día de la semana y encontremos el número de canciones reproducidas el lunes, miércoles y viernes. Utiliza el mismo método que antes, pero ahora necesitamos una agrupación diferente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZMKjiJz_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#day_song_count = df.groupby(by='Day')['Track'].count()\n",
    "day_song_count = df.groupby(by='day')['track'].count()\n",
    "\n",
    "# Filtrar solo los días lunes, miércoles y viernes\n",
    "day_song_count_filtered = day_song_count[['Monday', 'Wednesday', 'Friday']]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(day_song_count_filtered)# Calcular las canciones reproducidas en cada uno de los tres días\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POzs8bGa_Zcu"
   },
   "source": [
    "Ya sabes cómo contar entradas agrupándolas por ciudad o día. Ahora necesitas escribir una función que pueda contar entradas según ambos criterios simultáneamente.\n",
    "\n",
    "Crea la función `number_tracks()` para calcular el número de canciones reproducidas en un determinado día **y** ciudad. La función debe aceptar dos parámetros:\n",
    "\n",
    "- `day`: un día de la semana para filtrar. Por ejemplo, `'Monday'` (lunes).\n",
    "- `city`: una ciudad para filtrar. Por ejemplo, `'Springfield'`.\n",
    "\n",
    "Dentro de la función, aplicarás un filtrado consecutivo con indexación lógica.\n",
    "\n",
    "Primero filtra los datos por día y luego filtra la tabla resultante por ciudad.\n",
    "\n",
    "Después de filtrar los datos por dos criterios, cuenta el número de valores de la columna 'user_id' en la tabla resultante. Este recuento representa el número de entradas que estás buscando. Guarda el resultado en una nueva variable y devuélvelo desde la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nz3GdQB1_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def number_tracks(day, city):\n",
    "    # Filtrar los datos por día y ciudad\n",
    "    #filtered_data = df[(df['Day'] == day) & (df['City'] == city)]\n",
    "    filtered_data = df[(df['day'] == day) & (df['city'] == city)]\n",
    "    \n",
    "    # Contar el número de entradas en la columna 'user_id' en los datos filtrados\n",
    "    track_count = filtered_data['user_id'].count()\n",
    "    \n",
    "    # Devolver el resultado\n",
    "    return track_count\n",
    "\n",
    "# Llamar a la función con ejemplo de parámetros\n",
    "result = number_tracks('Monday', 'Springfield')\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytf7xFrFJQ2r"
   },
   "source": [
    "Llama a `number_tracks()` seis veces, cambiando los valores de los parámetros para que recuperes los datos de ambas ciudades para cada uno de los tres días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJcRATNQ_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result_monday_springfield = number_tracks('Monday', 'Springfield')# El número de canciones reproducidas en Springfield el lunes\n",
    "result_monday_springfield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hq_ncZ5T_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result_monday_springfield = number_tracks('Monday', 'Shelbyville')# El número de canciones reproducidas en Shelbyville el lunes\n",
    "result_monday_springfield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NTy2VPU_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result_wednesday_springfield = number_tracks('Wednesday', 'Springfield')# El número de canciones reproducidas en Springfield el miércoles\n",
    "result_wednesday_springfield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2y3TAwo_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result_wednesday_springfield = number_tracks('Wednesday', 'Shelbyville')# El número de canciones reproducidas en Shelbyville el miércoles\n",
    "result_wednesday_springfield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYDw5u_K_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result_friday_springfield = number_tracks('Friday', 'Springfield')# El número de canciones reproducidas en Springfield el viernes\n",
    "result_friday_springfield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_yzFtW3_Zcu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result_friday_springfield = number_tracks('Friday', 'Shelbyville')# El número de canciones reproducidas en Shelbyville el viernes\n",
    "result_friday_springfield\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EgPIHYu_Zcu"
   },
   "source": [
    "**Conclusiones**\n",
    "\n",
    "`Comenta si la hipótesis es correcta o se debe rechazar. Explica tu razonamiento.` si los resultados muestran que hay diferencias claras en la cantidad de canciones reproducidas entre Springfield y Shelbyville en los diferentes días de la semana, podríamos aceptar la hipótesis de que las actividades musicales varían entre las ciudades. Si, por otro lado, las diferencias son mínimas o inexistentes, entonces rechazaríamos la hipótesis, ya que no habría evidencia suficiente para concluir que las preferencias musicales difieren significativamente entre las dos ciudades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykKQ0N65_Zcv"
   },
   "source": [
    "# Conclusiones <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjUwbHb3_Zcv"
   },
   "source": [
    "`Resume aquí tus conclusiones sobre la hipótesis.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azLHu64yOIp7"
   },
   "source": [
    "### Nota\n",
    "En proyectos de investigación reales, la prueba de hipótesis estadística es más precisa y cuantitativa. También ten en cuenta que no siempre se pueden sacar conclusiones sobre una ciudad entera a partir de datos de una sola fuente.\n",
    "\n",
    "Aprenderás más sobre la prueba de hipótesis en el sprint de análisis estadístico de datos."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 362,
    "start_time": "2025-01-18T09:08:54.888Z"
   },
   {
    "duration": 188,
    "start_time": "2025-01-18T09:08:55.373Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-18T09:08:55.995Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-18T09:09:20.402Z"
   },
   {
    "duration": 112,
    "start_time": "2025-01-18T09:09:25.789Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-18T09:10:03.604Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-18T09:10:04.773Z"
   },
   {
    "duration": 94,
    "start_time": "2025-01-18T09:10:10.118Z"
   },
   {
    "duration": 95,
    "start_time": "2025-01-18T09:10:51.994Z"
   },
   {
    "duration": 94,
    "start_time": "2025-01-18T09:10:53.427Z"
   },
   {
    "duration": 95,
    "start_time": "2025-01-18T09:10:55.993Z"
   },
   {
    "duration": 92,
    "start_time": "2025-01-18T09:10:57.723Z"
   },
   {
    "duration": 127,
    "start_time": "2025-01-18T09:11:11.861Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-18T09:11:45.871Z"
   },
   {
    "duration": 116,
    "start_time": "2025-01-18T09:11:53.295Z"
   },
   {
    "duration": 106,
    "start_time": "2025-01-18T09:11:57.922Z"
   },
   {
    "duration": 41,
    "start_time": "2025-01-18T09:12:53.640Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-18T09:12:54.919Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-18T09:12:57.685Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-18T09:14:41.140Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-18T09:14:57.212Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-18T09:15:15.232Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-18T09:15:23.227Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-18T09:16:14.346Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-18T09:16:19.458Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-18T09:16:22.568Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-18T09:16:55.538Z"
   },
   {
    "duration": 51,
    "start_time": "2025-01-18T09:17:03.249Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-18T09:18:06.278Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-18T09:18:11.581Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-18T09:20:08.176Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-18T09:22:35.553Z"
   },
   {
    "duration": 321,
    "start_time": "2025-01-18T09:22:39.781Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-18T09:22:47.919Z"
   },
   {
    "duration": 259,
    "start_time": "2025-01-21T10:47:48.222Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-21T10:47:48.894Z"
   },
   {
    "duration": 106,
    "start_time": "2025-01-21T10:47:59.778Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-21T10:48:01.215Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-21T10:48:02.321Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-21T10:48:05.092Z"
   },
   {
    "duration": 93,
    "start_time": "2025-01-21T10:48:21.916Z"
   },
   {
    "duration": 93,
    "start_time": "2025-01-21T10:48:22.848Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-21T10:48:23.914Z"
   },
   {
    "duration": 93,
    "start_time": "2025-01-21T10:48:24.855Z"
   },
   {
    "duration": 116,
    "start_time": "2025-01-21T10:48:28.179Z"
   },
   {
    "duration": 117,
    "start_time": "2025-01-21T10:48:29.044Z"
   },
   {
    "duration": 178,
    "start_time": "2025-01-21T10:48:30.004Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-21T10:48:34.376Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-21T10:48:42.445Z"
   },
   {
    "duration": 47,
    "start_time": "2025-01-21T10:48:58.843Z"
   },
   {
    "duration": 78,
    "start_time": "2025-01-21T10:49:01.327Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-21T10:49:07.006Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-21T10:49:11.010Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:49:12.987Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-21T10:49:15.393Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:49:21.278Z"
   },
   {
    "duration": 108,
    "start_time": "2025-01-21T10:49:24.372Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-21T10:49:36.662Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-21T10:49:47.204Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-21T10:50:02.231Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-21T10:50:04.011Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-21T10:50:04.231Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-21T10:50:06.268Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-21T10:50:06.448Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-21T10:50:06.639Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:50:06.808Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-21T10:50:13.388Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-21T10:50:17.165Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:50:21.061Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-21T10:50:31.966Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-21T10:50:35.481Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-21T10:50:39.093Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-21T10:52:46.458Z"
   },
   {
    "duration": 85,
    "start_time": "2025-01-21T10:53:49.058Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-21T10:53:53.892Z"
   },
   {
    "duration": 92,
    "start_time": "2025-01-21T10:53:54.154Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-21T10:53:54.591Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-21T10:53:54.901Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-21T10:53:55.956Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-21T10:53:56.549Z"
   },
   {
    "duration": 89,
    "start_time": "2025-01-21T10:53:56.882Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-21T10:53:57.197Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-21T10:53:57.507Z"
   },
   {
    "duration": 113,
    "start_time": "2025-01-21T10:53:58.290Z"
   },
   {
    "duration": 113,
    "start_time": "2025-01-21T10:53:58.933Z"
   },
   {
    "duration": 20,
    "start_time": "2025-01-21T10:53:59.628Z"
   },
   {
    "duration": 53,
    "start_time": "2025-01-21T10:54:00.464Z"
   },
   {
    "duration": 48,
    "start_time": "2025-01-21T10:54:00.760Z"
   },
   {
    "duration": 80,
    "start_time": "2025-01-21T10:54:01.076Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-21T10:54:01.954Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-21T10:54:02.483Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:54:02.870Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-21T10:54:03.237Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-21T10:54:05.205Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-21T10:54:05.749Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-21T10:54:06.277Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-21T10:54:07.001Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:54:07.701Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-21T10:54:07.931Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:54:08.205Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-21T10:54:08.418Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-21T10:54:08.627Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-21T10:54:40.225Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-21T10:54:42.218Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-21T10:54:43.541Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-21T10:55:47.191Z"
   }
  ],
  "colab": {
   "collapsed_sections": [
    "E0vqbgi9ay0H",
    "VUC88oWjTJw2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
