{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario general del revisor</b> <a class=\"tocSkip\"></a><br />\nStatus del proyecto: <b>Aprobado</b>\n    \nAun hacian falta algunas correcciones, te he ayudado con eso y ahora el proyecto funciona correctamente.\n    \nContin\u00faa esforzandote y mucho \u00e9xito en el siguiente Sprint!    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "\u00a1Hola!<br />\nSoy **Francisco Cort\u00e9s**, estoy contento de revisar tu proyecto y ser parte de tu proceso de aprendizaje.\nA lo largo del texto, har\u00e9 algunas observaciones sobre mejoras en el c\u00f3digo y tambi\u00e9n har\u00e9 comentarios sobre tus percepciones sobre el tema. Si existe alg\u00fan error en el c\u00f3digo, no te preocupes, estoy aqu\u00ed para ayudarte a mejorarlo, en la primera iteraci\u00f3n te lo se\u00f1alar\u00e9 para que tengas la oportunidad de corregirlo, pero si a\u00fan no encuentras una soluci\u00f3n para esta tarea, te dar\u00e9 una pista m\u00e1s precisa en la pr\u00f3xima iteraci\u00f3n y tambi\u00e9n algunos ejemplos pr\u00e1cticos. Estar\u00e9 abierto a retroalimentaci\u00f3n y discusiones sobre el tema.<br />\nEncontrar\u00e1s mis comentarios a continuaci\u00f3n - **por favor no los muevas, modifiques o borres**.\nRevisar\u00e9 cuidadosamente tu c\u00f3digo para comprobar que se han cumplido con los requisitos y te proporcionar\u00e9 mis comentarios en cajas verdes, amarillas o rojas como esta:\n\n<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSi la ejecuci\u00f3n fue perfecta succesfully.\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSi existe alguna recomendaci\u00f3n para que tu c\u00f3digo mejore.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSi existen correcciones necesarias para cumplir con los requisitos. El trabajo no puede ser aceptado si hay alguna caja roja.\n</div>\n\nPuedes responderme de la siguiente manera:\n\n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante.</b> <a class=\"tocSkip\"></a>\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "E0vqbgi9ay0H"}, "source": "# D\u00e9jame escuchar la m\u00fasica"}, {"cell_type": "markdown", "metadata": {"id": "fhq_eyov_Zcs"}, "source": "# Contenido <a id='back'></a>\n\n* [Introducci\u00f3n](#intro)\n* [Etapa 1. Descripci\u00f3n de los datos](#data_review)\n    * [Conclusiones](#data_review_conclusions)\n* [Etapa 2. Preprocesamiento de datos](#data_preprocessing)\n    * [2.1 Estilo del encabezado](#header_style)\n    * [2.2 Valores ausentes](#missing_values)\n    * [2.3 Duplicados](#duplicates)\n    * [2.4 Conclusiones](#data_preprocessing_conclusions)\n* [Etapa 3. Prueba de hip\u00f3tesis](#hypothesis)\n    * [3.1 Hip\u00f3tesis 1: actividad de los usuarios y las usuarias en las dos ciudades](#activity)\n* [Conclusiones](#end)"}, {"cell_type": "markdown", "metadata": {"id": "VUC88oWjTJw2"}, "source": "## Introducci\u00f3n <a id='intro'></a>\nComo analista de datos, tu trabajo consiste en analizar datos para extraer informaci\u00f3n valiosa y tomar decisiones basadas en ellos. Esto implica diferentes etapas, como la descripci\u00f3n general de los datos, el preprocesamiento y la prueba de hip\u00f3tesis.\n\nSiempre que investigamos, necesitamos formular hip\u00f3tesis que despu\u00e9s podamos probar. A veces aceptamos estas hip\u00f3tesis; otras veces, las rechazamos. Para tomar las decisiones correctas, una empresa debe ser capaz de entender si est\u00e1 haciendo las suposiciones correctas.\n\nEn este proyecto, comparar\u00e1s las preferencias musicales de las ciudades de Springfield y Shelbyville. Estudiar\u00e1s datos reales de transmisi\u00f3n de m\u00fasica online para probar la hip\u00f3tesis a continuaci\u00f3n y comparar el comportamiento de los usuarios y las usuarias de estas dos ciudades.\n\n### Objetivo:\nPrueba la hip\u00f3tesis:\n1. La actividad de los usuarios y las usuarias difiere seg\u00fan el d\u00eda de la semana y dependiendo de la ciudad.\n\n\n### Etapas\nLos datos del comportamiento del usuario se almacenan en el archivo `/datasets/music_project_en.csv`. No hay ninguna informaci\u00f3n sobre la calidad de los datos, as\u00ed que necesitar\u00e1s examinarlos antes de probar la hip\u00f3tesis.\n\nPrimero, evaluar\u00e1s la calidad de los datos y ver\u00e1s si los problemas son significativos. Entonces, durante el preprocesamiento de datos, tomar\u00e1s en cuenta los problemas m\u00e1s cr\u00edticos.\n\nTu proyecto consistir\u00e1 en tres etapas:\n 1. Descripci\u00f3n de los datos.\n 2. Preprocesamiento de datos.\n 3. Prueba de hip\u00f3tesis.\n\n\n\n\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "hDt6pg-Rw-1U"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "Ml1hmfXC_Zcs"}, "source": "## Etapa 1. Descripci\u00f3n de los datos <a id='data_review'></a>\n\nAbre los datos y exam\u00ednalos."}, {"cell_type": "markdown", "metadata": {"id": "57eAOGIz_Zcs"}, "source": "Necesitar\u00e1s `pandas`, as\u00ed que imp\u00f3rtalo."}, {"cell_type": "code", "execution_count": 41, "metadata": {"id": "AXN7PHPN_Zcs", "trusted": true}, "outputs": [], "source": "import pandas as pd # Importar pandas\n"}, {"cell_type": "markdown", "metadata": {"id": "SG23P8tt_Zcs"}, "source": "Lee el archivo `music_project_en.csv` de la carpeta `/datasets/` y gu\u00e1rdalo en la variable `df`:"}, {"cell_type": "code", "execution_count": 42, "metadata": {"id": "fFVu7vqh_Zct", "trusted": true}, "outputs": [], "source": "#Leer el archivo y almacenarlo en df\ndf = pd.read_csv('/datasets/music_project_en.csv')\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\nLa manera de leer los datos es erronea, lo he corregido para que puedas ver la diferencia\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "rDoOMd3uTqnZ"}, "source": "Muestra las 10 primeras filas de la tabla:"}, {"cell_type": "code", "execution_count": 43, "metadata": {"id": "oWTVX3gW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     userID                        Track            artist   genre  \\\n0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n1  55204538  Delayed Because of Accident  Andreas R\u00f6nnberg    rock   \n2    20EC38            Funicul\u00ec funicul\u00e0       Mario Lanza     pop   \n3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n4  E2DC1FAE                  Soul People        Space Echo   dance   \n5  842029A1                       Chains          Obladaet  rusrap   \n6  4CB90AA5                         True      Roman Messer   dance   \n7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n8  8FA1D3BE                     L\u2019estate       Julia Dalia  ruspop   \n9  E772D5C0                    Pessimist               NaN   dance   \n\n        City        time        Day  \n0  Shelbyville  20:28:33  Wednesday  \n1  Springfield  14:07:09     Friday  \n2  Shelbyville  20:58:07  Wednesday  \n3  Shelbyville  08:37:09     Monday  \n4  Springfield  08:34:34     Monday  \n5  Shelbyville  13:09:41     Friday  \n6  Springfield  13:00:07  Wednesday  \n7  Springfield  20:47:49  Wednesday  \n8  Springfield  09:17:40     Friday  \n9  Shelbyville  21:20:49  Wednesday  \n"}], "source": "print(df.head(10))# Obtener las 10 primeras filas de la tabla df\n"}, {"cell_type": "markdown", "metadata": {"id": "EO73Kwic_Zct"}, "source": "Obt\u00e9n la informaci\u00f3n general sobre la tabla con un comando. Conoces el m\u00e9todo que muestra la informaci\u00f3n general que necesitamos."}, {"cell_type": "code", "execution_count": 44, "metadata": {"id": "DSf2kIb-_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "(65079, 7)\n"}], "source": "print(df.shape)# Obtener la informaci\u00f3n general sobre nuestros datos\n"}, {"cell_type": "markdown", "metadata": {"id": "TaQ2Iwbr_Zct"}, "source": "Estas son nuestras observaciones sobre la tabla. Contiene siete columnas. Almacenan los mismos tipos de datos: `object`.\n\nSeg\u00fan la documentaci\u00f3n:\n- `' userID'`: identificador del usuario o la usuaria;\n- `'Track'`: t\u00edtulo de la canci\u00f3n;\n- `'artist'`: nombre del artista;\n- `'genre'`: g\u00e9nero de la pista;\n- `'City'`: ciudad del usuario o la usuaria;\n- `'time'`: la hora exacta en la que se reprodujo la canci\u00f3n;\n- `'Day'`: d\u00eda de la semana.\n\nPodemos ver tres problemas con el estilo en los encabezados de la tabla:\n1. Algunos encabezados est\u00e1n en may\u00fasculas, otros en min\u00fasculas.\n2. Hay espacios en algunos encabezados.\n3. `Detecta el tercer problema por tu cuenta y descr\u00edbelo aqu\u00ed`.\n\nEl mal uso de las comillas en algunos nombres.\n"}, {"cell_type": "markdown", "metadata": {"id": "MCB6-dXG_Zct"}, "source": "### Escribe observaciones de tu parte. Estas son algunas de las preguntas que pueden ser \u00fatiles: <a id='data_review_conclusions'></a>\n\n`1.   \u00bfQu\u00e9 tipo de datos tenemos a nuestra disposici\u00f3n en las filas? \u00bfY c\u00f3mo podemos entender lo que almacenan las columnas?`\nCada fila representa una interacci\u00f3n de usuario, como la reproducci\u00f3n de una canci\u00f3n. Contiene informaci\u00f3n sobre el usuario, la canci\u00f3n reproducida, el artista, el g\u00e9nero, la ubicaci\u00f3n del usuario, el momento exacto de la reproducci\u00f3n y el d\u00eda de la semana.\n\nColumnas:\n'userID': Identificador \u00fanico del usuario, lo que nos permite rastrear las acciones de un usuario individual.\n'Track': T\u00edtulo de la canci\u00f3n reproducida, importante para analizar preferencias musicales.\n'artist': Artista de la canci\u00f3n, \u00fatil para medir popularidad.\n'genre': G\u00e9nero musical, relevante para clasificar preferencias musicales.\n'City': Ciudad del usuario, lo que permite an\u00e1lisis geogr\u00e1ficos.\n'time': Hora exacta de la reproducci\u00f3n, que puede usarse para patrones temporales.\n'Day': D\u00eda de la semana, \u00fatil para explorar tendencias semanales.\n\n`2.   \u00bfHay suficientes datos para proporcionar respuestas a nuestra hip\u00f3tesis o necesitamos m\u00e1s informaci\u00f3n?`\nLos datos incluyen informaci\u00f3n detallada sobre canciones, artistas, g\u00e9neros, ubicaci\u00f3n y tiempo, lo cual es \u00fatil para analizar h\u00e1bitos de escucha y tendencias geogr\u00e1ficas/temporales.\nLimitaciones:\nNo hay datos sobre la duraci\u00f3n de la escucha o si la canci\u00f3n fue escuchada completamente.\nNo se incluye informaci\u00f3n demogr\u00e1fica del usuario (como edad o g\u00e9nero), lo que podr\u00eda ser relevante dependiendo de la hip\u00f3tesis.\nNo se detalla si hay datos incompletos o representatividad insuficiente en ciertas ciudades o g\u00e9neros.\n\n`3.   \u00bfNotaste alg\u00fan problema en los datos, como valores ausentes, duplicados o tipos de datos incorrectos?`\nProblemas observados:\nLos encabezados tienen inconsistencias de formato (espacios, may\u00fasculas/min\u00fasculas, comillas).\nTodas las columnas tienen el tipo de datos object, lo que podr\u00eda no ser apropiado para columnas como 'time' (deber\u00eda ser un tipo de tiempo) o 'Day' (posiblemente una categor\u00eda).\nProblemas por verificar:\nValores ausentes: Es importante comprobar si hay columnas o filas con valores nulos que podr\u00edan afectar el an\u00e1lisis.\nDuplicados: Si hay filas duplicadas, podr\u00edan inflar o sesgar los resultados.\nDatos inconsistentes: Por ejemplo, errores tipogr\u00e1ficos en 'genre' o 'City' podr\u00edan dificultar el agrupamiento."}, {"cell_type": "markdown", "metadata": {"id": "3eL__vcwViOi"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "SjYF6Ub9_Zct"}, "source": "## Etapa 2. Preprocesamiento de datos <a id='data_preprocessing'></a>\n\nEl objetivo aqu\u00ed es preparar los datos para que sean analizados.\nEl primer paso es resolver cualquier problema con los encabezados. Luego podemos avanzar a los valores ausentes y duplicados. Empecemos.\n\nCorrige el formato en los encabezados de la tabla.\n"}, {"cell_type": "markdown", "metadata": {"id": "dIaKXr29_Zct"}, "source": "### Estilo del encabezado <a id='header_style'></a>\nMuestra los encabezados de la tabla (los nombres de las columnas):"}, {"cell_type": "code", "execution_count": 45, "metadata": {"id": "oKOTdF_Q_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"}], "source": "# Mostrar los encabezados originales\nprint(df.columns)\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\nLos datos se deben leer solo una vez al inicio del proyecto, si se vuelven a leer todo el progreso que hayas hecho se pierde\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "zj5534cv_Zct"}, "source": "Cambia los encabezados de la tabla de acuerdo con las reglas del buen estilo:\n* Todos los caracteres deben ser min\u00fasculas.\n* Elimina los espacios.\n* Si el nombre tiene varias palabras, utiliza snake_case."}, {"cell_type": "markdown", "metadata": {"id": "Xu0zkfe5zNJe"}, "source": "Anteriormente, aprendiste acerca de la forma autom\u00e1tica de cambiar el nombre de las columnas. Vamos a aplicarla ahora. Utiliza el bucle for para iterar sobre los nombres de las columnas y poner todos los caracteres en min\u00fasculas. Cuando hayas terminado, vuelve a mostrar los encabezados de la tabla:"}, {"cell_type": "code", "execution_count": 46, "metadata": {"id": "6I_RwwMhzM4e", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Encabezados originales:\nIndex(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n\nEncabezados despu\u00e9s de poner todo en min\u00fasculas:\nIndex(['  userid', 'track', 'artist', 'genre', '  city  ', 'time', 'day'], dtype='object')\n"}], "source": "import pandas as pd\n\n# Leer el archivo CSV\ndf = pd.read_csv('/datasets/music_project_en.csv')\n\n# Mostrar los encabezados originales\nprint(\"Encabezados originales:\")\nprint(df.columns)\n\n# Cambiar los nombres de las columnas a min\u00fasculas utilizando un bucle for\ndf.columns = [col.lower() for col in df.columns]\n\n# Mostrar los encabezados despu\u00e9s de convertir a min\u00fasculas\nprint(\"\\nEncabezados despu\u00e9s de poner todo en min\u00fasculas:\")\nprint(df.columns)\n"}, {"cell_type": "markdown", "metadata": {"id": "pweIRxjSzPYW"}, "source": "Ahora, utilizando el mismo m\u00e9todo, elimina los espacios al principio y al final de los nombres de las columnas e imprime los nombres de las columnas nuevamente:"}, {"cell_type": "code", "execution_count": 47, "metadata": {"id": "vVQXbFyJzSYl", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Encabezados originales:\nIndex(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n\nEncabezados despu\u00e9s de eliminar los espacios y poner todo en min\u00fasculas:\nIndex(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "import pandas as pd\n\n# Leer el archivo CSV\ndf = pd.read_csv('/datasets/music_project_en.csv')\n\n# Mostrar los encabezados originales\nprint(\"Encabezados originales:\")\nprint(df.columns)\n\n# Cambiar los nombres de las columnas a min\u00fasculas y eliminar espacios al principio y al final\ndf.columns = [col.strip().lower() for col in df.columns]\n\n# Mostrar los encabezados despu\u00e9s de eliminar los espacios y convertir a min\u00fasculas\nprint(\"\\nEncabezados despu\u00e9s de eliminar los espacios y poner todo en min\u00fasculas:\")\nprint(df.columns)\n"}, {"cell_type": "markdown", "metadata": {"id": "yCb8MW1JzURd"}, "source": "Necesitamos aplicar la regla de snake_case a la columna `userid`. Debe ser `user_id`. Cambia el nombre de esta columna y muestra los nombres de todas las columnas cuando hayas terminado."}, {"cell_type": "code", "execution_count": 48, "metadata": {"id": "ISlFqs5y_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Encabezados originales:\nIndex(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n\nEncabezados despu\u00e9s de aplicar snake_case a 'userID':\nIndex(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "import pandas as pd\n\n# Leer el archivo CSV\ndf = pd.read_csv('/datasets/music_project_en.csv')\n\n# Mostrar los encabezados originales\nprint(\"Encabezados originales:\")\nprint(df.columns)\n\n# Cambiar los nombres de las columnas a min\u00fasculas y eliminar espacios al principio y al final\ndf.columns = [col.strip().lower() for col in df.columns]\n\n# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\ndf.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n\n# Mostrar los encabezados despu\u00e9s del cambio\nprint(\"\\nEncabezados despu\u00e9s de aplicar snake_case a 'userID':\")\nprint(df.columns)\n"}, {"cell_type": "markdown", "metadata": {"id": "1dqbh00J_Zct"}, "source": "Comprueba el resultado. Muestra los encabezados una vez m\u00e1s:"}, {"cell_type": "code", "execution_count": 49, "metadata": {"id": "d4NOAmTW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Encabezados originales:\nIndex(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n\nEncabezados despu\u00e9s de aplicar snake_case a 'userID':\nIndex(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "import pandas as pd\n\n# Leer el archivo CSV\ndf = pd.read_csv('/datasets/music_project_en.csv')\n\n# Mostrar los encabezados originales\nprint(\"Encabezados originales:\")\nprint(df.columns)\n\n# Cambiar los nombres de las columnas a min\u00fasculas y eliminar espacios al principio y al final\ndf.columns = [col.strip().lower() for col in df.columns]\n\n# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\ndf.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n\n# Mostrar los encabezados despu\u00e9s del cambio\nprint(\"\\nEncabezados despu\u00e9s de aplicar snake_case a 'userID':\")\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\nEn todas las celdas anteriores los datos fueron leidos en cada paso, lo cual es incorrecto\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\nBuena manera de corregir y reemplazar los nombres de las columnas\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "xYJk6ksJVpOl"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "5ISfbcfY_Zct"}, "source": "### Valores ausentes <a id='missing_values'></a>\n Primero, encuentra el n\u00famero de valores ausentes en la tabla. Debes utilizar dos m\u00e9todos en una secuencia para obtener el n\u00famero de valores ausentes."}, {"cell_type": "code", "execution_count": 50, "metadata": {"id": "RskX29qr_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "        user_id track artist genre         city      time        day\n15     E3C5756F   NaN    NaN   NaN  Springfield  09:24:51     Monday\n35     A8AE9169   NaN    NaN   NaN  Springfield  08:56:10     Monday\n161    364C85C0   NaN    NaN   NaN  Springfield  20:06:58     Monday\n210    C4990C90   NaN    NaN   NaN  Springfield  20:09:56     Monday\n216    22B27E80   NaN    NaN   NaN  Springfield  13:34:16     Monday\n...         ...   ...    ...   ...          ...       ...        ...\n64792  7D9627FD   NaN    NaN   NaN  Springfield  08:57:15     Monday\n64810  36CDD10A   NaN    NaN  folk  Springfield  13:44:53  Wednesday\n64930  A8AE9169   NaN    NaN   NaN  Springfield  08:54:17     Friday\n64950  414F229D   NaN    NaN   NaN  Springfield  14:41:26     Monday\n65021  83831D51   NaN    NaN   hip  Shelbyville  20:15:36     Friday\n\n[1343 rows x 7 columns]\n\nDataFrame despu\u00e9s de reemplazar los valores ausentes:\n        user_id                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina               NaN   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[65079 rows x 7 columns]\n\nN\u00famero de valores ausentes en todo el DataFrame:\nuser_id       0\ntrack         0\nartist     7567\ngenre      1198\ncity          0\ntime          0\nday           0\ndtype: int64\n"}], "source": "import pandas as pd\n\n# Leer el archivo CSV\ndf = pd.read_csv('/datasets/music_project_en.csv')\n\n# Cambiar los nombres de las columnas a min\u00fasculas y eliminar espacios\ndf.columns = [col.strip().lower() for col in df.columns]\n\n# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\ndf.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n\n# Mostrar los valores ausentes en una columna espec\u00edfica (por ejemplo 'track')\nprint(df[df[\"track\"].isna()])\n\n# Rellenar los valores ausentes con 'unknown'\ndf[\"track\"].fillna('unknown', inplace=True)\n\n# Mostrar el DataFrame despu\u00e9s de reemplazar los valores ausentes\nprint(\"\\nDataFrame despu\u00e9s de reemplazar los valores ausentes:\")\nprint(df)\n\n# Ver el n\u00famero total de valores ausentes\nprint(\"\\nN\u00famero de valores ausentes en todo el DataFrame:\")\nprint(df.isna().sum())# Calcular el n\u00famero de valores ausentes\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\nAqu\u00ed vuelves a leer los datos y repites los pasos anteriores\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "qubhgnlO_Zct"}, "source": "No todos los valores ausentes afectan a la investigaci\u00f3n. Por ejemplo, los valores ausentes en `track` y `artist` no son cruciales. Simplemente puedes reemplazarlos con valores predeterminados como el string `'unknown'` (desconocido).\n\nPero los valores ausentes en `'genre'` pueden afectar la comparaci\u00f3n entre las preferencias musicales de Springfield y Shelbyville. En la vida real, ser\u00eda \u00fatil saber las razones por las cuales hay datos ausentes e intentar recuperarlos. Pero no tenemos esa oportunidad en este proyecto. As\u00ed que tendr\u00e1s que:\n* rellenar estos valores ausentes con un valor predeterminado;\n* evaluar cu\u00e1nto podr\u00edan afectar los valores ausentes a tus c\u00f3mputos;"}, {"cell_type": "markdown", "metadata": {"id": "fSv2laPA_Zct"}, "source": "Reemplazar los valores ausentes en las columnas `'track'`, `'artist'` y `'genre'` con el string `'unknown'`. Como mostramos anteriormente en las lecciones, la mejor forma de hacerlo es crear una lista que almacene los nombres de las columnas donde se necesita el reemplazo. Luego, utiliza esta lista e itera sobre las columnas donde se necesita el reemplazo haciendo el propio reemplazo."}, {"cell_type": "code", "execution_count": 51, "metadata": {"id": "KplB5qWs_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\nDataFrame despu\u00e9s de reemplazar los valores ausentes:\n        user_id                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina           unknown   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[65079 rows x 7 columns]\n\nN\u00famero de valores ausentes en todo el DataFrame:\nuser_id    0\ntrack      0\nartist     0\ngenre      0\ncity       0\ntime       0\nday        0\ndtype: int64\n"}], "source": "\n#python\n#Copy\n#Edit\nimport pandas as pd\n\n# Leer el archivo CSV\ndf = pd.read_csv('/datasets/music_project_en.csv')\n\n# Cambiar los nombres de las columnas a min\u00fasculas y eliminar espacios\ndf.columns = [col.strip().lower() for col in df.columns]\n\n# Renombrar 'userid' a 'user_id' para aplicar la regla de snake_case\ndf.rename(columns={\"userid\": \"user_id\"}, inplace=True)\n\n# Crear una lista de las columnas donde se necesita reemplazar los valores ausentes\ncolumns_to_fill = ['track', 'artist', 'genre']\n\n# Iterar sobre las columnas y reemplazar los valores ausentes con 'unknown'\nfor column in columns_to_fill:\n    df[column].fillna('unknown', inplace=True)\n\n# Mostrar el DataFrame despu\u00e9s de reemplazar los valores ausentes\nprint(\"\\nDataFrame despu\u00e9s de reemplazar los valores ausentes:\")\nprint(df)\n\n# Ver el n\u00famero total de valores ausentes\nprint(\"\\nN\u00famero de valores ausentes en todo el DataFrame:\")\nprint(df.isna().sum())# Bucle en los encabezados reemplazando los valores ausentes con 'unknown'\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\nAqu\u00ed vuelves a leer los datos y a repetir pasos anteriores\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\nBuena manera de reemplazar los valores ausentes en el dataframe\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "Ilsm-MZo_Zct"}, "source": "Ahora comprueba el resultado para asegurarte de que despu\u00e9s del reemplazo no haya valores ausentes en el conjunto de datos. Para hacer esto, cuenta los valores ausentes nuevamente."}, {"cell_type": "code", "execution_count": 52, "metadata": {"id": "Tq4nYRX4_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "N\u00famero de valores ausentes por columna:\nuser_id    0\ntrack      0\nartist     0\ngenre      0\ncity       0\ntime       0\nday        0\ndtype: int64\n\nN\u00famero total de valores ausentes en el DataFrame: 0\n"}], "source": "#lumna\nmissing_counts = df.isna().sum()\n\n# Mostrar el n\u00famero de valores ausentes por columna\nprint(\"N\u00famero de valores ausentes por columna:\")\nprint(missing_counts)\n\n# Contar el total de valores ausentes en el DataFrame\ntotal_missing = missing_counts.sum()\n\nprint(f\"\\nN\u00famero total de valores ausentes en el DataFrame: {total_missing}\")# Contar valores ausentes\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorregido!<br/>\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\nComo el dataframe fue leido otra vez, el progreso se perdio y vuelves a tener valores ausentes\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "74ZIBmq9VrsK"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "BWKRtBJ3_Zct"}, "source": "### Duplicados <a id='duplicates'></a>\nEncuentra el n\u00famero de duplicados expl\u00edcitos en la tabla. Una vez m\u00e1s, debes aplicar dos m\u00e9todos en una secuencia para obtener la cantidad de duplicados expl\u00edcitos."}, {"cell_type": "code", "execution_count": 53, "metadata": {"id": "36eES_S0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "El n\u00famero de duplicados expl\u00edcitos es: 3826\n"}], "source": "duplicates = df.duplicated()\n\n# Contar el n\u00famero de duplicados\nduplicate_count = duplicates.sum()\n\n# Mostrar el n\u00famero de duplicados\nprint(f\"El n\u00famero de duplicados expl\u00edcitos es: {duplicate_count}\")# Contar duplicados expl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "Ot25h6XR_Zct"}, "source": "Ahora, elimina todos los duplicados. Para ello, llama al m\u00e9todo que hace exactamente esto."}, {"cell_type": "code", "execution_count": 54, "metadata": {"id": "exFHq6tt_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "        user_id                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina           unknown   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[61253 rows x 7 columns]\n"}], "source": "df_cleaned = df.drop_duplicates()\n\n# Mostrar el DataFrame sin duplicados\nprint(df_cleaned)# Eliminar duplicados expl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "Im2YwBEG_Zct"}, "source": "Comprobemos ahora si eliminamos con \u00e9xito todos los duplicados. Cuenta los duplicados expl\u00edcitos una vez m\u00e1s para asegurarte de haberlos eliminado todos:"}, {"cell_type": "code", "execution_count": 55, "metadata": {"id": "-8PuNWQ0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "El n\u00famero de duplicados expl\u00edcitos despu\u00e9s de eliminar los duplicados es: 0\n"}], "source": "# Eliminar duplicados y guardar el resultado en un nuevo DataFrame\n#df_cleaned = df.drop_duplicates()\ndf = df.drop_duplicates()\n\n# Ahora, usa df_cleaned para cualquier operaci\u00f3n posterior\n#duplicates_after_cleaning = df_cleaned.duplicated().sum()\nduplicates_after_cleaning = df.duplicated().sum()\n\n# Mostrar el n\u00famero de duplicados despu\u00e9s de la limpieza\nprint(f\"El n\u00famero de duplicados expl\u00edcitos despu\u00e9s de eliminar los duplicados es: {duplicates_after_cleaning}\")"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\nTe he ayuado a corregir este error\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\n```\ndf_cleaned = df.drop_duplicates()\n```\n\nEsa manera es la forma correcta de eliminar los duplicados, pero el dataframe limpio sin duplicados lo estas guardando e `df_cleaned`, este es el dataframe que deber\u00edas usar a partir de este punto, otra alternativa es guardar los cambios en el dataframe original\n\n```\ndf = df.drop_duplicates()\n```\n\nDe etsa manera el dataframe original es alterado y se eliminan sus duplicados\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "QlFBsxAr_Zct"}, "source": "Ahora queremos deshacernos de los duplicados impl\u00edcitos en la columna `genre`. Por ejemplo, el nombre de un g\u00e9nero se puede escribir de varias formas. Dichos errores tambi\u00e9n pueden afectar al resultado."}, {"cell_type": "markdown", "metadata": {"id": "eSjWwsOh_Zct"}, "source": "Para hacerlo, primero mostremos una lista de nombres de g\u00e9nero \u00fanicos, ordenados en orden alfab\u00e9tico. Para ello:\n* Extrae la columna `genre` del DataFrame.\n* Llama al m\u00e9todo que devolver\u00e1 todos los valores \u00fanicos en la columna extra\u00edda.\n"}, {"cell_type": "code", "execution_count": 56, "metadata": {"id": "JIUcqzZN_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "G\u00e9neros \u00fanicos ordenados alfab\u00e9ticamente:\n['acid' 'acoustic' 'action' 'adult' 'africa' 'afrikaans' 'alternative'\n 'ambient' 'americana' 'animated' 'anime' 'arabesk' 'arabic' 'arena'\n 'argentinetango' 'art' 'audiobook' 'avantgarde' 'ax\u00e9' 'baile' 'balkan'\n 'beats' 'bigroom' 'black' 'bluegrass' 'blues' 'bollywood' 'bossa'\n 'brazilian' 'breakbeat' 'breaks' 'broadway' 'cantautori' 'cantopop'\n 'canzone' 'caribbean' 'caucasian' 'celtic' 'chamber' 'children' 'chill'\n 'chinese' 'choral' 'christian' 'christmas' 'classical' 'classicmetal'\n 'club' 'colombian' 'comedy' 'conjazz' 'contemporary' 'country' 'cuban'\n 'dance' 'dancehall' 'dancepop' 'dark' 'death' 'deep' 'deutschrock'\n 'deutschspr' 'dirty' 'disco' 'dnb' 'documentary' 'downbeat' 'downtempo'\n 'drum' 'dub' 'dubstep' 'eastern' 'easy' 'electronic' 'electropop' 'emo'\n 'entehno' 'epicmetal' 'estrada' 'ethnic' 'eurofolk' 'european'\n 'experimental' 'extrememetal' 'fado' 'film' 'fitness' 'flamenco' 'folk'\n 'folklore' 'folkmetal' 'folkrock' 'folktronica' 'forr\u00f3' 'frankreich'\n 'franz\u00f6sisch' 'french' 'funk' 'future' 'gangsta' 'garage' 'german'\n 'ghazal' 'gitarre' 'glitch' 'gospel' 'gothic' 'grime' 'grunge' 'gypsy'\n 'handsup' \"hard'n'heavy\" 'hardcore' 'hardstyle' 'hardtechno' 'hip'\n 'hip-hop' 'hiphop' 'historisch' 'holiday' 'hop' 'horror' 'house' 'idm'\n 'independent' 'indian' 'indie' 'indipop' 'industrial' 'inspirational'\n 'instrumental' 'international' 'irish' 'jam' 'japanese' 'jazz' 'jewish'\n 'jpop' 'jungle' 'k-pop' 'karadeniz' 'karaoke' 'kayokyoku' 'korean'\n 'laiko' 'latin' 'latino' 'leftfield' 'local' 'lounge' 'loungeelectronic'\n 'lovers' 'malaysian' 'mandopop' 'marschmusik' 'meditative'\n 'mediterranean' 'melodic' 'metal' 'metalcore' 'mexican' 'middle'\n 'minimal' 'miscellaneous' 'modern' 'mood' 'mpb' 'muslim' 'native'\n 'neoklassik' 'neue' 'new' 'newage' 'newwave' 'nu' 'nujazz' 'numetal'\n 'oceania' 'old' 'opera' 'orchestral' 'other' 'piano' 'pop'\n 'popelectronic' 'popeurodance' 'post' 'posthardcore' 'postrock' 'power'\n 'progmetal' 'progressive' 'psychedelic' 'punjabi' 'punk' 'quebecois'\n 'ragga' 'ram' 'rancheras' 'rap' 'rave' 'reggae' 'reggaeton' 'regional'\n 'relax' 'religious' 'retro' 'rhythm' 'rnb' 'rnr' 'rock' 'rockabilly'\n 'romance' 'roots' 'ruspop' 'rusrap' 'rusrock' 'salsa' 'samba' 'schlager'\n 'self' 'sertanejo' 'shoegazing' 'showtunes' 'singer' 'ska' 'slow'\n 'smooth' 'soul' 'soulful' 'sound' 'soundtrack' 'southern' 'specialty'\n 'speech' 'spiritual' 'sport' 'stonerrock' 'surf' 'swing' 'synthpop'\n 's\u00e4ngerportrait' 'tango' 'tanzorchester' 'taraftar' 'tech' 'techno'\n 'thrash' 'top' 'traditional' 'tradjazz' 'trance' 'tribal' 'trip'\n 'triphop' 'tropical' 't\u00fcrk' 't\u00fcrk\u00e7e' 'unknown' 'urban' 'uzbek' 'vari\u00e9t\u00e9'\n 'vi' 'videogame' 'vocal' 'western' 'world' 'worldbeat' '\u00ef\u00ee\u00ef']\n"}], "source": "import numpy as np\n\n# Obtener la columna de g\u00e9neros\ngenre_column = df['genre']\n\n# Obtener los valores \u00fanicos\nunique_genres = genre_column.unique()\n\n# Unificar los tipos de dato a cadena de texto\nunique_genres = unique_genres.astype(str)\n\n# Ordenar los g\u00e9neros alfab\u00e9ticamente usando NumPy\nsorted_unique_genres = np.sort(unique_genres)\n\n# Imprimir los g\u00e9neros \u00fanicos ordenados alfab\u00e9ticamente\nprint(\"G\u00e9neros \u00fanicos ordenados alfab\u00e9ticamente:\")\nprint(sorted_unique_genres)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorregido!<br/>\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\n\nLa manera de ordenar los elementos dentro de una lista de numpy es la siguiente\n\n```\n# Se importa la libreria de numpy\nimport numpy as np\n# Primero unificar los tipos de dato que hay dentro del arreglo\nunique_genres = unique_genres.astype(str)\n# Despu\u00e9s ya podemos ordenarlo\nsorted_unique_genres = np.sort(unique_genres)\n# Imprimimos el resultado\nprint(sorted_arr)\n```\n\n</div>\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "qej-Qmuo_Zct"}, "source": "Busca en la lista para encontrar duplicados impl\u00edcitos del g\u00e9nero `hiphop`. Estos pueden ser nombres escritos incorrectamente o nombres alternativos para el mismo g\u00e9nero.\n\nVer\u00e1s los siguientes duplicados impl\u00edcitos:\n* `hip`\n* `hop`\n* `hip-hop`\n\nPara deshacerte de ellos, crea una funci\u00f3n llamada `replace_wrong_genres()` con dos par\u00e1metros:\n* `wrong_genres=`: esta es una lista que contiene todos los valores que necesitas reemplazar.\n* `correct_genre=`: este es un string que vas a utilizar como reemplazo.\n\nComo resultado, la funci\u00f3n deber\u00eda corregir los nombres en la columna `'genre'` de la tabla `df`, es decir, remplazar cada valor de la lista `wrong_genres` por el valor en `correct_genre`.\n\nDentro del cuerpo de la funci\u00f3n, utiliza un bucle `'for'` para iterar sobre la lista de g\u00e9neros incorrectos, extrae la columna `'genre'` y aplica el m\u00e9todo `replace` para hacer correcciones."}, {"cell_type": "code", "execution_count": 69, "metadata": {"id": "ErNDkmns_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "G\u00e9neros \u00fanicos despu\u00e9s de la correcci\u00f3n:\n['acid', 'acoustic', 'action', 'adult', 'africa', 'afrikaans', 'alternative', 'ambient', 'americana', 'animated', 'anime', 'arabesk', 'arabic', 'arena', 'argentinetango', 'art', 'audiobook', 'avantgarde', 'ax\u00e9', 'baile', 'balkan', 'beats', 'bigroom', 'black', 'bluegrass', 'blues', 'bollywood', 'bossa', 'brazilian', 'breakbeat', 'breaks', 'broadway', 'cantautori', 'cantopop', 'canzone', 'caribbean', 'caucasian', 'celtic', 'chamber', 'children', 'chill', 'chinese', 'choral', 'christian', 'christmas', 'classical', 'classicmetal', 'club', 'colombian', 'comedy', 'conjazz', 'contemporary', 'country', 'cuban', 'dance', 'dancehall', 'dancepop', 'dark', 'death', 'deep', 'deutschrock', 'deutschspr', 'dirty', 'disco', 'dnb', 'documentary', 'downbeat', 'downtempo', 'drum', 'dub', 'dubstep', 'eastern', 'easy', 'electronic', 'electropop', 'emo', 'entehno', 'epicmetal', 'estrada', 'ethnic', 'eurofolk', 'european', 'experimental', 'extrememetal', 'fado', 'film', 'fitness', 'flamenco', 'folk', 'folklore', 'folkmetal', 'folkrock', 'folktronica', 'forr\u00f3', 'frankreich', 'franz\u00f6sisch', 'french', 'funk', 'future', 'gangsta', 'garage', 'german', 'ghazal', 'gitarre', 'glitch', 'gospel', 'gothic', 'grime', 'grunge', 'gypsy', 'handsup', \"hard'n'heavy\", 'hardcore', 'hardstyle', 'hardtechno', 'hiphop', 'historisch', 'holiday', 'horror', 'house', 'idm', 'independent', 'indian', 'indie', 'indipop', 'industrial', 'inspirational', 'instrumental', 'international', 'irish', 'jam', 'japanese', 'jazz', 'jewish', 'jpop', 'jungle', 'k-pop', 'karadeniz', 'karaoke', 'kayokyoku', 'korean', 'laiko', 'latin', 'latino', 'leftfield', 'local', 'lounge', 'loungeelectronic', 'lovers', 'malaysian', 'mandopop', 'marschmusik', 'meditative', 'mediterranean', 'melodic', 'metal', 'metalcore', 'mexican', 'middle', 'minimal', 'miscellaneous', 'modern', 'mood', 'mpb', 'muslim', 'native', 'neoklassik', 'neue', 'new', 'newage', 'newwave', 'nu', 'nujazz', 'numetal', 'oceania', 'old', 'opera', 'orchestral', 'other', 'piano', 'pop', 'popelectronic', 'popeurodance', 'post', 'posthardcore', 'postrock', 'power', 'progmetal', 'progressive', 'psychedelic', 'punjabi', 'punk', 'quebecois', 'ragga', 'ram', 'rancheras', 'rap', 'rave', 'reggae', 'reggaeton', 'regional', 'relax', 'religious', 'retro', 'rhythm', 'rnb', 'rnr', 'rock', 'rockabilly', 'romance', 'roots', 'ruspop', 'rusrap', 'rusrock', 'salsa', 'samba', 'schlager', 'self', 'sertanejo', 'shoegazing', 'showtunes', 'singer', 'ska', 'slow', 'smooth', 'soul', 'soulful', 'sound', 'soundtrack', 'southern', 'specialty', 'speech', 'spiritual', 'sport', 'stonerrock', 'surf', 'swing', 'synthpop', 's\u00e4ngerportrait', 'tango', 'tanzorchester', 'taraftar', 'tech', 'techno', 'thrash', 'top', 'traditional', 'tradjazz', 'trance', 'tribal', 'trip', 'triphop', 'tropical', 't\u00fcrk', 't\u00fcrk\u00e7e', 'unknown', 'urban', 'uzbek', 'vari\u00e9t\u00e9', 'vi', 'videogame', 'vocal', 'western', 'world', 'worldbeat', '\u00ef\u00ee\u00ef']\n"}], "source": "def replace_wrong_genres(wrong_genres, correct_genre):\n    for genre in wrong_genres:\n        # Reemplazar los g\u00e9neros incorrectos con el correcto\n        df['genre'] = df['genre'].replace(genre, correct_genre)\n\n# Lista de g\u00e9neros incorrectos que queremos reemplazar\nwrong_genres = ['hip', 'hop', 'hip-hop']\n\n# G\u00e9nero correcto que vamos a usar como reemplazo\ncorrect_genre = 'hip-hop'\n\n# Llamar a la funci\u00f3n para reemplazar los g\u00e9neros incorrectos\nreplace_wrong_genres(wrong_genres, correct_genre)\n\n# Verificar los g\u00e9neros despu\u00e9s de la correcci\u00f3n\nunique_genres_after_correction = sorted(df['genre'].unique())\nprint(\"G\u00e9neros \u00fanicos despu\u00e9s de la correcci\u00f3n:\")\nprint(unique_genres_after_correction)# Funci\u00f3n para reemplazar duplicados impl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "aDoBJxbA_Zct"}, "source": "Ahora, llama a `replace_wrong_genres()` y p\u00e1sale tales argumentos para que retire los duplicados impl\u00edcitos (`hip`, `hop` y `hip-hop`) y los reemplace por `hiphop`:"}, {"cell_type": "code", "execution_count": 70, "metadata": {"id": "YN5i2hpmSo09", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "G\u00e9neros \u00fanicos despu\u00e9s de la correcci\u00f3n:\n['acid', 'acoustic', 'action', 'adult', 'africa', 'afrikaans', 'alternative', 'ambient', 'americana', 'animated', 'anime', 'arabesk', 'arabic', 'arena', 'argentinetango', 'art', 'audiobook', 'avantgarde', 'ax\u00e9', 'baile', 'balkan', 'beats', 'bigroom', 'black', 'bluegrass', 'blues', 'bollywood', 'bossa', 'brazilian', 'breakbeat', 'breaks', 'broadway', 'cantautori', 'cantopop', 'canzone', 'caribbean', 'caucasian', 'celtic', 'chamber', 'children', 'chill', 'chinese', 'choral', 'christian', 'christmas', 'classical', 'classicmetal', 'club', 'colombian', 'comedy', 'conjazz', 'contemporary', 'country', 'cuban', 'dance', 'dancehall', 'dancepop', 'dark', 'death', 'deep', 'deutschrock', 'deutschspr', 'dirty', 'disco', 'dnb', 'documentary', 'downbeat', 'downtempo', 'drum', 'dub', 'dubstep', 'eastern', 'easy', 'electronic', 'electropop', 'emo', 'entehno', 'epicmetal', 'estrada', 'ethnic', 'eurofolk', 'european', 'experimental', 'extrememetal', 'fado', 'film', 'fitness', 'flamenco', 'folk', 'folklore', 'folkmetal', 'folkrock', 'folktronica', 'forr\u00f3', 'frankreich', 'franz\u00f6sisch', 'french', 'funk', 'future', 'gangsta', 'garage', 'german', 'ghazal', 'gitarre', 'glitch', 'gospel', 'gothic', 'grime', 'grunge', 'gypsy', 'handsup', \"hard'n'heavy\", 'hardcore', 'hardstyle', 'hardtechno', 'hiphop', 'historisch', 'holiday', 'horror', 'house', 'idm', 'independent', 'indian', 'indie', 'indipop', 'industrial', 'inspirational', 'instrumental', 'international', 'irish', 'jam', 'japanese', 'jazz', 'jewish', 'jpop', 'jungle', 'k-pop', 'karadeniz', 'karaoke', 'kayokyoku', 'korean', 'laiko', 'latin', 'latino', 'leftfield', 'local', 'lounge', 'loungeelectronic', 'lovers', 'malaysian', 'mandopop', 'marschmusik', 'meditative', 'mediterranean', 'melodic', 'metal', 'metalcore', 'mexican', 'middle', 'minimal', 'miscellaneous', 'modern', 'mood', 'mpb', 'muslim', 'native', 'neoklassik', 'neue', 'new', 'newage', 'newwave', 'nu', 'nujazz', 'numetal', 'oceania', 'old', 'opera', 'orchestral', 'other', 'piano', 'pop', 'popelectronic', 'popeurodance', 'post', 'posthardcore', 'postrock', 'power', 'progmetal', 'progressive', 'psychedelic', 'punjabi', 'punk', 'quebecois', 'ragga', 'ram', 'rancheras', 'rap', 'rave', 'reggae', 'reggaeton', 'regional', 'relax', 'religious', 'retro', 'rhythm', 'rnb', 'rnr', 'rock', 'rockabilly', 'romance', 'roots', 'ruspop', 'rusrap', 'rusrock', 'salsa', 'samba', 'schlager', 'self', 'sertanejo', 'shoegazing', 'showtunes', 'singer', 'ska', 'slow', 'smooth', 'soul', 'soulful', 'sound', 'soundtrack', 'southern', 'specialty', 'speech', 'spiritual', 'sport', 'stonerrock', 'surf', 'swing', 'synthpop', 's\u00e4ngerportrait', 'tango', 'tanzorchester', 'taraftar', 'tech', 'techno', 'thrash', 'top', 'traditional', 'tradjazz', 'trance', 'tribal', 'trip', 'triphop', 'tropical', 't\u00fcrk', 't\u00fcrk\u00e7e', 'unknown', 'urban', 'uzbek', 'vari\u00e9t\u00e9', 'vi', 'videogame', 'vocal', 'western', 'world', 'worldbeat', '\u00ef\u00ee\u00ef']\n"}], "source": "replace_wrong_genres(wrong_genres=['hip', 'hop', 'hip-hop'], correct_genre='hiphop')\n\n# Verificar los g\u00e9neros \u00fanicos despu\u00e9s de la correcci\u00f3n\nunique_genres_after_correction = sorted(df['genre'].unique())\nprint(\"G\u00e9neros \u00fanicos despu\u00e9s de la correcci\u00f3n:\")\nprint(unique_genres_after_correction)# Eliminar duplicados impl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "zQKF16_RG15m"}, "source": "Aseg\u00farate de que los nombres duplicados han sido eliminados. Muestra la lista de valores \u00fanicos de la columna `'genre'` una vez m\u00e1s:"}, {"cell_type": "code", "execution_count": 71, "metadata": {"id": "wvixALnFG15m", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "G\u00e9neros \u00fanicos despu\u00e9s de la correcci\u00f3n:\n['acid', 'acoustic', 'action', 'adult', 'africa', 'afrikaans', 'alternative', 'ambient', 'americana', 'animated', 'anime', 'arabesk', 'arabic', 'arena', 'argentinetango', 'art', 'audiobook', 'avantgarde', 'ax\u00e9', 'baile', 'balkan', 'beats', 'bigroom', 'black', 'bluegrass', 'blues', 'bollywood', 'bossa', 'brazilian', 'breakbeat', 'breaks', 'broadway', 'cantautori', 'cantopop', 'canzone', 'caribbean', 'caucasian', 'celtic', 'chamber', 'children', 'chill', 'chinese', 'choral', 'christian', 'christmas', 'classical', 'classicmetal', 'club', 'colombian', 'comedy', 'conjazz', 'contemporary', 'country', 'cuban', 'dance', 'dancehall', 'dancepop', 'dark', 'death', 'deep', 'deutschrock', 'deutschspr', 'dirty', 'disco', 'dnb', 'documentary', 'downbeat', 'downtempo', 'drum', 'dub', 'dubstep', 'eastern', 'easy', 'electronic', 'electropop', 'emo', 'entehno', 'epicmetal', 'estrada', 'ethnic', 'eurofolk', 'european', 'experimental', 'extrememetal', 'fado', 'film', 'fitness', 'flamenco', 'folk', 'folklore', 'folkmetal', 'folkrock', 'folktronica', 'forr\u00f3', 'frankreich', 'franz\u00f6sisch', 'french', 'funk', 'future', 'gangsta', 'garage', 'german', 'ghazal', 'gitarre', 'glitch', 'gospel', 'gothic', 'grime', 'grunge', 'gypsy', 'handsup', \"hard'n'heavy\", 'hardcore', 'hardstyle', 'hardtechno', 'hiphop', 'historisch', 'holiday', 'horror', 'house', 'idm', 'independent', 'indian', 'indie', 'indipop', 'industrial', 'inspirational', 'instrumental', 'international', 'irish', 'jam', 'japanese', 'jazz', 'jewish', 'jpop', 'jungle', 'k-pop', 'karadeniz', 'karaoke', 'kayokyoku', 'korean', 'laiko', 'latin', 'latino', 'leftfield', 'local', 'lounge', 'loungeelectronic', 'lovers', 'malaysian', 'mandopop', 'marschmusik', 'meditative', 'mediterranean', 'melodic', 'metal', 'metalcore', 'mexican', 'middle', 'minimal', 'miscellaneous', 'modern', 'mood', 'mpb', 'muslim', 'native', 'neoklassik', 'neue', 'new', 'newage', 'newwave', 'nu', 'nujazz', 'numetal', 'oceania', 'old', 'opera', 'orchestral', 'other', 'piano', 'pop', 'popelectronic', 'popeurodance', 'post', 'posthardcore', 'postrock', 'power', 'progmetal', 'progressive', 'psychedelic', 'punjabi', 'punk', 'quebecois', 'ragga', 'ram', 'rancheras', 'rap', 'rave', 'reggae', 'reggaeton', 'regional', 'relax', 'religious', 'retro', 'rhythm', 'rnb', 'rnr', 'rock', 'rockabilly', 'romance', 'roots', 'ruspop', 'rusrap', 'rusrock', 'salsa', 'samba', 'schlager', 'self', 'sertanejo', 'shoegazing', 'showtunes', 'singer', 'ska', 'slow', 'smooth', 'soul', 'soulful', 'sound', 'soundtrack', 'southern', 'specialty', 'speech', 'spiritual', 'sport', 'stonerrock', 'surf', 'swing', 'synthpop', 's\u00e4ngerportrait', 'tango', 'tanzorchester', 'taraftar', 'tech', 'techno', 'thrash', 'top', 'traditional', 'tradjazz', 'trance', 'tribal', 'trip', 'triphop', 'tropical', 't\u00fcrk', 't\u00fcrk\u00e7e', 'unknown', 'urban', 'uzbek', 'vari\u00e9t\u00e9', 'vi', 'videogame', 'vocal', 'western', 'world', 'worldbeat', '\u00ef\u00ee\u00ef']\n"}], "source": "unique_genres_after_correction = sorted(df['genre'].unique())\nprint(\"G\u00e9neros \u00fanicos despu\u00e9s de la correcci\u00f3n:\")\nprint(unique_genres_after_correction)# Comprobaci\u00f3n de duplicados impl\u00edcitos\n"}, {"cell_type": "markdown", "metadata": {"id": "ALgNbvF3VtPA"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto, se eliminaron los duplicados explicitos de manera adecuada y los duplicados implicitos se reemplazaron por un valor estandarizado, los duplicados implicitos por lo general son m\u00e1s dif\u00edciles de encontrar debido a que se requiere contexto/conocimiento de los datos que se estan analizando, bien hecho\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "jz6a9-7HQUDd"}, "source": "### Tus observaciones <a id='data_preprocessing_conclusions'></a>\n\n`Describe brevemente lo que has notado al analizar duplicados, c\u00f3mo abordaste sus eliminaciones y qu\u00e9 resultados obtuviste.`\n\nAl analizar los duplicados en el DataFrame, observ\u00e9 que hab\u00eda dos tipos de duplicados:\n\nDuplicados expl\u00edcitos: Es decir, filas exactas que se repet\u00edan en el DataFrame. Para eliminarlas, utilic\u00e9 el m\u00e9todo drop_duplicates() de Pandas\n\nDuplicados impl\u00edcitos en la columna 'genre': Algunos g\u00e9neros, como \"hip\", \"hop\" y \"hip-hop\", se escrib\u00edan de formas inconsistentes, lo que podr\u00eda afectar el an\u00e1lisis de las preferencias musicales. Para solucionar esto, cre\u00e9 la funci\u00f3n replace_wrong_genres().\n\nTras eliminar los duplicados expl\u00edcitos, confirm\u00e9 que no quedaban filas repetidas en el DataFrame.\nDespu\u00e9s de corregir los duplicados impl\u00edcitos en la columna genre, "}, {"cell_type": "markdown", "metadata": {"id": "eK1es74rVujj"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "WttZHXH0SqKk"}, "source": "## Etapa 3. Prueba de hip\u00f3tesis <a id='hypothesis'></a>"}, {"cell_type": "markdown", "metadata": {"id": "Im936VVi_Zcu"}, "source": "### Hip\u00f3tesis: comparar el comportamiento del usuario o la usuaria en las dos ciudades <a id='activity'></a>"}, {"cell_type": "markdown", "metadata": {"id": "nwt_MuaL_Zcu"}, "source": "La hip\u00f3tesis afirma que existen diferencias en la forma en que los usuarios y las usuarias de Springfield y Shelbyville consumen m\u00fasica. Para comprobar esto, usa los datos de tres d\u00edas de la semana: lunes, mi\u00e9rcoles y viernes.\n\n* Agrupa a los usuarios y las usuarias por ciudad.\n* Compara el n\u00famero de canciones que cada grupo reprodujo el lunes, el mi\u00e9rcoles y el viernes.\n"}, {"cell_type": "markdown", "metadata": {"id": "8Dw_YMmT_Zcu"}, "source": "Realiza cada c\u00e1lculo por separado.\n\nEl primer paso es evaluar la actividad del usuario en cada ciudad. Recuerda las etapas dividir-aplicar-combinar de las que hablamos anteriormente en la lecci\u00f3n. Tu objetivo ahora es agrupar los datos por ciudad, aplicar el m\u00e9todo apropiado para contar durante la etapa de aplicaci\u00f3n y luego encontrar la cantidad de canciones reproducidas en cada grupo especificando la columna para obtener el recuento.\n\nA continuaci\u00f3n se muestra un ejemplo de c\u00f3mo deber\u00eda verse el resultado final:\n`df.groupby(by='....')['column'].method()`Realiza cada c\u00e1lculo por separado.\n\nPara evaluar la actividad de los usuarios y las usuarias en cada ciudad, agrupa los datos por ciudad y encuentra la cantidad de canciones reproducidas en cada grupo.\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\n\nSe corrigi\u00f3 `city` pero hizo falta hacer el cambio tambi\u00e9n en `track`, te he ayudado a corregirlo  \n\n</div>\n\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCuidado!<br/>\n\n\nA partir de este punto debes cambiar los nombres de columna anteriores por los nuevos, ejemplo:\n    \n`City` pasa a ser `city`    \n\n</div>\n\n\n"}, {"cell_type": "code", "execution_count": 72, "metadata": {"id": "0_Qs96oh_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "city\nShelbyville    18512\nSpringfield    42741\nName: track, dtype: int64\n"}], "source": "#city_song_count = df.groupby(by='city')['Track'].count()\ncity_song_count = df.groupby(by='city')['track'].count()\n\n# Mostrar el resultado\nprint(city_song_count)# Contar las canciones reproducidas en cada ciudad\n"}, {"cell_type": "markdown", "metadata": {"id": "t_Qx-3NewAnK"}, "source": "`Comenta tus observaciones aqu\u00ed  Este c\u00f3digo te dar\u00e1 la cantidad de canciones reproducidas por ciudad`"}, {"cell_type": "markdown", "metadata": {"id": "dzli3w8o_Zcu"}, "source": "Ahora agrupemos los datos por d\u00eda de la semana y encontremos el n\u00famero de canciones reproducidas el lunes, mi\u00e9rcoles y viernes. Utiliza el mismo m\u00e9todo que antes, pero ahora necesitamos una agrupaci\u00f3n diferente.\n"}, {"cell_type": "code", "execution_count": 61, "metadata": {"id": "uZMKjiJz_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "day\nMonday       21354\nWednesday    18059\nFriday       21840\nName: track, dtype: int64\n"}], "source": "#day_song_count = df.groupby(by='Day')['Track'].count()\nday_song_count = df.groupby(by='day')['track'].count()\n\n# Filtrar solo los d\u00edas lunes, mi\u00e9rcoles y viernes\nday_song_count_filtered = day_song_count[['Monday', 'Wednesday', 'Friday']]\n\n# Mostrar el resultado\nprint(day_song_count_filtered)# Calcular las canciones reproducidas en cada uno de los tres d\u00edas\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\nBuena manera de agrupar los datos, buenas observaciones\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "cC2tNrlL_Zcu"}, "source": "`Comenta tus observaciones aqu\u00ed`Este c\u00f3digo te dar\u00e1 la cantidad de canciones reproducidas solo en esos d\u00edas espec\u00edficos"}, {"cell_type": "markdown", "metadata": {"id": "POzs8bGa_Zcu"}, "source": "Ya sabes c\u00f3mo contar entradas agrup\u00e1ndolas por ciudad o d\u00eda. Ahora necesitas escribir una funci\u00f3n que pueda contar entradas seg\u00fan ambos criterios simult\u00e1neamente.\n\nCrea la funci\u00f3n `number_tracks()` para calcular el n\u00famero de canciones reproducidas en un determinado d\u00eda **y** ciudad. La funci\u00f3n debe aceptar dos par\u00e1metros:\n\n- `day`: un d\u00eda de la semana para filtrar. Por ejemplo, `'Monday'` (lunes).\n- `city`: una ciudad para filtrar. Por ejemplo, `'Springfield'`.\n\nDentro de la funci\u00f3n, aplicar\u00e1s un filtrado consecutivo con indexaci\u00f3n l\u00f3gica.\n\nPrimero filtra los datos por d\u00eda y luego filtra la tabla resultante por ciudad.\n\nDespu\u00e9s de filtrar los datos por dos criterios, cuenta el n\u00famero de valores de la columna 'user_id' en la tabla resultante. Este recuento representa el n\u00famero de entradas que est\u00e1s buscando. Guarda el resultado en una nueva variable y devu\u00e9lvelo desde la funci\u00f3n."}, {"cell_type": "code", "execution_count": 62, "metadata": {"id": "Nz3GdQB1_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "15740\n"}], "source": "def number_tracks(day, city):\n    # Filtrar los datos por d\u00eda y ciudad\n    #filtered_data = df[(df['Day'] == day) & (df['City'] == city)]\n    filtered_data = df[(df['day'] == day) & (df['city'] == city)]\n    \n    # Contar el n\u00famero de entradas en la columna 'user_id' en los datos filtrados\n    track_count = filtered_data['user_id'].count()\n    \n    # Devolver el resultado\n    return track_count\n\n# Llamar a la funci\u00f3n con ejemplo de par\u00e1metros\nresult = number_tracks('Monday', 'Springfield')\n\n# Mostrar el resultado\nprint(result)"}, {"cell_type": "markdown", "metadata": {"id": "ytf7xFrFJQ2r"}, "source": "Llama a `number_tracks()` seis veces, cambiando los valores de los par\u00e1metros para que recuperes los datos de ambas ciudades para cada uno de los tres d\u00edas."}, {"cell_type": "code", "execution_count": 63, "metadata": {"id": "rJcRATNQ_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "15740"}, "execution_count": 63, "metadata": {}, "output_type": "execute_result"}], "source": "result_monday_springfield = number_tracks('Monday', 'Springfield')# El n\u00famero de canciones reproducidas en Springfield el lunes\nresult_monday_springfield\n"}, {"cell_type": "code", "execution_count": 64, "metadata": {"id": "hq_ncZ5T_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "5614"}, "execution_count": 64, "metadata": {}, "output_type": "execute_result"}], "source": "result_monday_springfield = number_tracks('Monday', 'Shelbyville')# El n\u00famero de canciones reproducidas en Shelbyville el lunes\nresult_monday_springfield\n"}, {"cell_type": "code", "execution_count": 65, "metadata": {"id": "_NTy2VPU_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "11056"}, "execution_count": 65, "metadata": {}, "output_type": "execute_result"}], "source": "result_wednesday_springfield = number_tracks('Wednesday', 'Springfield')# El n\u00famero de canciones reproducidas en Springfield el mi\u00e9rcoles\nresult_wednesday_springfield\n"}, {"cell_type": "code", "execution_count": 66, "metadata": {"id": "j2y3TAwo_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "7003"}, "execution_count": 66, "metadata": {}, "output_type": "execute_result"}], "source": "result_wednesday_springfield = number_tracks('Wednesday', 'Shelbyville')# El n\u00famero de canciones reproducidas en Shelbyville el mi\u00e9rcoles\nresult_wednesday_springfield\n"}, {"cell_type": "code", "execution_count": 67, "metadata": {"id": "vYDw5u_K_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "15945"}, "execution_count": 67, "metadata": {}, "output_type": "execute_result"}], "source": "result_friday_springfield = number_tracks('Friday', 'Springfield')# El n\u00famero de canciones reproducidas en Springfield el viernes\nresult_friday_springfield\n"}, {"cell_type": "code", "execution_count": 68, "metadata": {"id": "8_yzFtW3_Zcu", "trusted": true}, "outputs": [{"data": {"text/plain": "5895"}, "execution_count": 68, "metadata": {}, "output_type": "execute_result"}], "source": "result_friday_springfield = number_tracks('Friday', 'Shelbyville')# El n\u00famero de canciones reproducidas en Shelbyville el viernes\nresult_friday_springfield\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nCorrecto, muy buena manera de probar la hipotesis, comprobando (en este caso) que los grupos son similares\n \n</div>"}, {"cell_type": "markdown", "metadata": {"id": "-EgPIHYu_Zcu"}, "source": "**Conclusiones**\n\n`Comenta si la hip\u00f3tesis es correcta o se debe rechazar. Explica tu razonamiento.` si los resultados muestran que hay diferencias claras en la cantidad de canciones reproducidas entre Springfield y Shelbyville en los diferentes d\u00edas de la semana, podr\u00edamos aceptar la hip\u00f3tesis de que las actividades musicales var\u00edan entre las ciudades. Si, por otro lado, las diferencias son m\u00ednimas o inexistentes, entonces rechazar\u00edamos la hip\u00f3tesis, ya que no habr\u00eda evidencia suficiente para concluir que las preferencias musicales difieren significativamente entre las dos ciudades."}, {"cell_type": "markdown", "metadata": {}, "source": "# Comentario general del revisor\n<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nHas realizado un buen trabajo, me doy cuenta de que has aplicado los conocimientos que has adquirido durante el curso, los procedimientos realizados son correctos.<br/>\n \nLas decisiones que tomas a lo largo del proyecto me parecen acertadas y te hacen ir por un buen camino, lo que termina en un analisis bastante acertado.    \n<br/>\nLas conclusiones finales a las que llegas estan respaldadas con los procedimientos que has realizado a lo largo del proyecto, me parecen bastante acertadas y el lenguaje que usas es adecuado para que cualquier persona las pueda entender.\n<br/> <br/> \n\n    \n    \nEste tipo de analisis ayudar\u00e1 al negocio a enfocarse en partes especificas de los distintos eventos que los usuarios toman para llegar a realizar una compra, en este caso se pueden enfocar en la parte donde se pierden la mayor\u00eda de usuarios que es el pasar de la pantalla principal a la pantalla de ofertas. Se pueden crear distintas maneras de generar mas enganche para que cada vez m\u00e1s personas pasen de una etapa a la siguiente.<br/>\nContin\u00faa con el buen trabajo y mucho \u00e9xito en el siguiente Sprint!\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "p7nFQajCVw5B"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "ykKQ0N65_Zcv"}, "source": "# Conclusiones <a id='end'></a>"}, {"cell_type": "markdown", "metadata": {"id": "tjUwbHb3_Zcv"}, "source": "`Resume aqu\u00ed tus conclusiones sobre la hip\u00f3tesis.`"}, {"cell_type": "markdown", "metadata": {"id": "azLHu64yOIp7"}, "source": "### Nota\nEn proyectos de investigaci\u00f3n reales, la prueba de hip\u00f3tesis estad\u00edstica es m\u00e1s precisa y cuantitativa. Tambi\u00e9n ten en cuenta que no siempre se pueden sacar conclusiones sobre una ciudad entera a partir de datos de una sola fuente.\n\nAprender\u00e1s m\u00e1s sobre la prueba de hip\u00f3tesis en el sprint de an\u00e1lisis estad\u00edstico de datos."}, {"cell_type": "markdown", "metadata": {"id": "Ju4AHDSgV1FE"}, "source": "[Volver a Contenidos](#back)"}], "metadata": {"ExecuteTimeLog": [{"duration": 362, "start_time": "2025-01-18T09:08:54.888Z"}, {"duration": 188, "start_time": "2025-01-18T09:08:55.373Z"}, {"duration": 12, "start_time": "2025-01-18T09:08:55.995Z"}, {"duration": 18, "start_time": "2025-01-18T09:09:20.402Z"}, {"duration": 112, "start_time": "2025-01-18T09:09:25.789Z"}, {"duration": 6, "start_time": "2025-01-18T09:10:03.604Z"}, {"duration": 3, "start_time": "2025-01-18T09:10:04.773Z"}, {"duration": 94, "start_time": "2025-01-18T09:10:10.118Z"}, {"duration": 95, "start_time": "2025-01-18T09:10:51.994Z"}, {"duration": 94, "start_time": "2025-01-18T09:10:53.427Z"}, {"duration": 95, "start_time": "2025-01-18T09:10:55.993Z"}, {"duration": 92, "start_time": "2025-01-18T09:10:57.723Z"}, {"duration": 127, "start_time": "2025-01-18T09:11:11.861Z"}, {"duration": 16, "start_time": "2025-01-18T09:11:45.871Z"}, {"duration": 116, "start_time": "2025-01-18T09:11:53.295Z"}, {"duration": 106, "start_time": "2025-01-18T09:11:57.922Z"}, {"duration": 41, "start_time": "2025-01-18T09:12:53.640Z"}, {"duration": 44, "start_time": "2025-01-18T09:12:54.919Z"}, {"duration": 37, "start_time": "2025-01-18T09:12:57.685Z"}, {"duration": 18, "start_time": "2025-01-18T09:14:41.140Z"}, {"duration": 15, "start_time": "2025-01-18T09:14:57.212Z"}, {"duration": 6, "start_time": "2025-01-18T09:15:15.232Z"}, {"duration": 13, "start_time": "2025-01-18T09:15:23.227Z"}, {"duration": 4, "start_time": "2025-01-18T09:16:14.346Z"}, {"duration": 13, "start_time": "2025-01-18T09:16:19.458Z"}, {"duration": 4, "start_time": "2025-01-18T09:16:22.568Z"}, {"duration": 12, "start_time": "2025-01-18T09:16:55.538Z"}, {"duration": 51, "start_time": "2025-01-18T09:17:03.249Z"}, {"duration": 2, "start_time": "2025-01-18T09:18:06.278Z"}, {"duration": 5, "start_time": "2025-01-18T09:18:11.581Z"}, {"duration": 3, "start_time": "2025-01-18T09:20:08.176Z"}, {"duration": 21, "start_time": "2025-01-18T09:22:35.553Z"}, {"duration": 321, "start_time": "2025-01-18T09:22:39.781Z"}, {"duration": 11, "start_time": "2025-01-18T09:22:47.919Z"}, {"duration": 259, "start_time": "2025-01-21T10:47:48.222Z"}, {"duration": 6, "start_time": "2025-01-21T10:47:48.894Z"}, {"duration": 106, "start_time": "2025-01-21T10:47:59.778Z"}, {"duration": 6, "start_time": "2025-01-21T10:48:01.215Z"}, {"duration": 2, "start_time": "2025-01-21T10:48:02.321Z"}, {"duration": 3, "start_time": "2025-01-21T10:48:05.092Z"}, {"duration": 93, "start_time": "2025-01-21T10:48:21.916Z"}, {"duration": 93, "start_time": "2025-01-21T10:48:22.848Z"}, {"duration": 91, "start_time": "2025-01-21T10:48:23.914Z"}, {"duration": 93, "start_time": "2025-01-21T10:48:24.855Z"}, {"duration": 116, "start_time": "2025-01-21T10:48:28.179Z"}, {"duration": 117, "start_time": "2025-01-21T10:48:29.044Z"}, {"duration": 178, "start_time": "2025-01-21T10:48:30.004Z"}, {"duration": 19, "start_time": "2025-01-21T10:48:34.376Z"}, {"duration": 42, "start_time": "2025-01-21T10:48:42.445Z"}, {"duration": 47, "start_time": "2025-01-21T10:48:58.843Z"}, {"duration": 78, "start_time": "2025-01-21T10:49:01.327Z"}, {"duration": 6, "start_time": "2025-01-21T10:49:07.006Z"}, {"duration": 12, "start_time": "2025-01-21T10:49:11.010Z"}, {"duration": 11, "start_time": "2025-01-21T10:49:12.987Z"}, {"duration": 6, "start_time": "2025-01-21T10:49:15.393Z"}, {"duration": 11, "start_time": "2025-01-21T10:49:21.278Z"}, {"duration": 108, "start_time": "2025-01-21T10:49:24.372Z"}, {"duration": 10, "start_time": "2025-01-21T10:49:36.662Z"}, {"duration": 10, "start_time": "2025-01-21T10:49:47.204Z"}, {"duration": 14, "start_time": "2025-01-21T10:50:02.231Z"}, {"duration": 13, "start_time": "2025-01-21T10:50:04.011Z"}, {"duration": 12, "start_time": "2025-01-21T10:50:04.231Z"}, {"duration": 9, "start_time": "2025-01-21T10:50:06.268Z"}, {"duration": 10, "start_time": "2025-01-21T10:50:06.448Z"}, {"duration": 12, "start_time": "2025-01-21T10:50:06.639Z"}, {"duration": 11, "start_time": "2025-01-21T10:50:06.808Z"}, {"duration": 13, "start_time": "2025-01-21T10:50:13.388Z"}, {"duration": 12, "start_time": "2025-01-21T10:50:17.165Z"}, {"duration": 11, "start_time": "2025-01-21T10:50:21.061Z"}, {"duration": 12, "start_time": "2025-01-21T10:50:31.966Z"}, {"duration": 15, "start_time": "2025-01-21T10:50:35.481Z"}, {"duration": 14, "start_time": "2025-01-21T10:50:39.093Z"}, {"duration": 4, "start_time": "2025-01-21T10:52:46.458Z"}, {"duration": 85, "start_time": "2025-01-21T10:53:49.058Z"}, {"duration": 3, "start_time": "2025-01-21T10:53:53.892Z"}, {"duration": 92, "start_time": "2025-01-21T10:53:54.154Z"}, {"duration": 5, "start_time": "2025-01-21T10:53:54.591Z"}, {"duration": 3, "start_time": "2025-01-21T10:53:54.901Z"}, {"duration": 3, "start_time": "2025-01-21T10:53:55.956Z"}, {"duration": 91, "start_time": "2025-01-21T10:53:56.549Z"}, {"duration": 89, "start_time": "2025-01-21T10:53:56.882Z"}, {"duration": 91, "start_time": "2025-01-21T10:53:57.197Z"}, {"duration": 91, "start_time": "2025-01-21T10:53:57.507Z"}, {"duration": 113, "start_time": "2025-01-21T10:53:58.290Z"}, {"duration": 113, "start_time": "2025-01-21T10:53:58.933Z"}, {"duration": 20, "start_time": "2025-01-21T10:53:59.628Z"}, {"duration": 53, "start_time": "2025-01-21T10:54:00.464Z"}, {"duration": 48, "start_time": "2025-01-21T10:54:00.760Z"}, {"duration": 80, "start_time": "2025-01-21T10:54:01.076Z"}, {"duration": 7, "start_time": "2025-01-21T10:54:01.954Z"}, {"duration": 12, "start_time": "2025-01-21T10:54:02.483Z"}, {"duration": 11, "start_time": "2025-01-21T10:54:02.870Z"}, {"duration": 6, "start_time": "2025-01-21T10:54:03.237Z"}, {"duration": 10, "start_time": "2025-01-21T10:54:05.205Z"}, {"duration": 9, "start_time": "2025-01-21T10:54:05.749Z"}, {"duration": 14, "start_time": "2025-01-21T10:54:06.277Z"}, {"duration": 13, "start_time": "2025-01-21T10:54:07.001Z"}, {"duration": 11, "start_time": "2025-01-21T10:54:07.701Z"}, {"duration": 12, "start_time": "2025-01-21T10:54:07.931Z"}, {"duration": 11, "start_time": "2025-01-21T10:54:08.205Z"}, {"duration": 13, "start_time": "2025-01-21T10:54:08.418Z"}, {"duration": 11, "start_time": "2025-01-21T10:54:08.627Z"}, {"duration": 10, "start_time": "2025-01-21T10:54:40.225Z"}, {"duration": 10, "start_time": "2025-01-21T10:54:42.218Z"}, {"duration": 5, "start_time": "2025-01-21T10:54:43.541Z"}, {"duration": 10, "start_time": "2025-01-21T10:55:47.191Z"}], "colab": {"collapsed_sections": ["E0vqbgi9ay0H", "VUC88oWjTJw2"], "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 1}